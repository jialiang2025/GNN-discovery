{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNOonIJ60cgxpRsC4jlG5DB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jialiang2025/GNN-discovery/blob/main/HVAE_for_Brain_Connecitivity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xZRkmvQE0EPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfbd67bf-7ab6-43d2-fcff-b411b2040359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ],
      "source": [
        "pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_to_graph(matrix):\n",
        "    matrix = torch.tensor(matrix, dtype=torch.float32)\n",
        "    edge_index = torch.nonzero(matrix, as_tuple=False).t().contiguous()\n",
        "    edge_attr = matrix[edge_index[0], edge_index[1]].unsqueeze(1)  # shape [num_edges, 1]\n",
        "    x = torch.eye(matrix.size(0))  # identity node features (64 x 64)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)"
      ],
      "metadata": {
        "id": "LHPsjPCK-pHy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Load diff_patient.npy\n",
        "# Assuming diff_patient.npy is already uploaded and available as per previous cells\n",
        "try:\n",
        "    diff_patient = np.load(\"diff_patient.npy\")\n",
        "except FileNotFoundError:\n",
        "    print(\"diff_patient.npy not found. Please upload the file.\")\n",
        "    uploaded = files.upload()\n",
        "    diff_patient = np.load(\"diff_patient.npy\")\n",
        "\n",
        "\n",
        "# 2. Load risk.npy\n",
        "# Assuming risk.npy is already uploaded and available as per previous cells\n",
        "try:\n",
        "    risk = np.load(\"risk.npy\", allow_pickle=True)\n",
        "except FileNotFoundError:\n",
        "    print(\"risk.npy not found. Please upload the file.\")\n",
        "    uploaded = files.upload()\n",
        "    risk = np.load(\"risk.npy\", allow_pickle=True)\n",
        "\n",
        "\n",
        "# 3. Convert risk to torch.long tensor\n",
        "risk_tensor = torch.tensor(risk, dtype=torch.long)\n",
        "\n",
        "\n",
        "# 3. Load IT.npy\n",
        "# Assuming IT.npy is already uploaded and available as per previous cells\n",
        "try:\n",
        "    IT = np.load(\"IT.npy\", allow_pickle=True)\n",
        "except FileNotFoundError:\n",
        "    print(\"IT.npy not found. Please upload the file.\")\n",
        "    uploaded = files.upload()\n",
        "    IT = np.load(\"IT.npy\", allow_pickle=True)\n",
        "\n",
        "\n",
        "# 3. Convert risk to torch.long tensor\n",
        "IT_tensor = torch.tensor(IT, dtype=torch.long)\n",
        "\n",
        "\n",
        "# Define the matrix_to_graph function (already defined in a previous cell, but included here for clarity if running this cell independently)\n",
        "# However, following the instructions, we should not repeat imports or definitions.\n",
        "# Assuming matrix_to_graph is available from a previous cell.\n",
        "# def matrix_to_graph(matrix):\n",
        "#     matrix = torch.tensor(matrix, dtype=torch.float32)\n",
        "#     edge_index = torch.nonzero(matrix, as_tuple=False).t().contiguous()\n",
        "#     edge_attr = matrix[edge_index[0], edge_index[1]].unsqueeze(1)  # shape [num_edges, 1]\n",
        "#     x = torch.eye(matrix.size(0))  # identity node features (64 x 64)\n",
        "#     return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "\n",
        "\n",
        "# 4. Create a list of PyTorch Geometric Data objects\n",
        "graphs = [matrix_to_graph(m) for m in diff_patient]\n",
        "\n",
        "\n",
        "# 5. Determine the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "# 6. Assign labels and move tensors to device\n",
        "for i, g in enumerate(graphs):\n",
        "    g.y = torch.tensor([risk_tensor[i]], dtype=torch.long)  # labels: 0 or 1 per patient\n",
        "    # Move the tensors within the Data object to the specified device\n",
        "    g.x = g.x.to(device)\n",
        "    g.edge_index = g.edge_index.to(device)\n",
        "    # Check if edge_attr exists and is not None before moving\n",
        "    if hasattr(g, 'edge_attr') and g.edge_attr is not None:\n",
        "        g.edge_attr = g.edge_attr.to(device)\n",
        "    g.y = g.y.to(device) # Also move the label to the device\n",
        "\n",
        "\n",
        "# 7. Create a DataLoader\n",
        "loader = DataLoader(graphs, batch_size=32, shuffle=True)\n",
        "\n",
        "print(f\"Number of graphs loaded: {len(graphs)}\")\n",
        "print(f\"Number of batches in DataLoader: {len(loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "Tki1sOAJ_L2b",
        "outputId": "e0982feb-847e-4308-ca31-43162bb3526a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diff_patient.npy not found. Please upload the file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b11dabca-153d-4987-ad07-0455bba349e7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b11dabca-153d-4987-ad07-0455bba349e7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving diff_patient.npy to diff_patient.npy\n",
            "risk.npy not found. Please upload the file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-428d4202-6d11-4de9-860a-4df60c822aca\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-428d4202-6d11-4de9-860a-4df60c822aca\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving risk.npy to risk.npy\n",
            "IT.npy not found. Please upload the file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-de2a6209-2906-40c5-8eb9-c160c3c2dff6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-de2a6209-2906-40c5-8eb9-c160c3c2dff6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IT.npy to IT.npy\n",
            "Using device: cuda\n",
            "Number of graphs loaded: 335\n",
            "Number of batches in DataLoader: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-582100245.py:77: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  loader = DataLoader(graphs, batch_size=32, shuffle=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the numerical range of the data\n",
        "data_min = np.min(diff_patient)\n",
        "data_max = np.max(diff_patient)\n",
        "print(f\"Numerical range of diff_patient.npy: [{data_min}, {data_max}]\")\n",
        "\n",
        "# Test for symmetry of each 64x64 matrix\n",
        "num_matrices = diff_patient.shape[0]\n",
        "symmetric_count = 0\n",
        "nonsymmetric_indices = []\n",
        "\n",
        "for i in range(num_matrices):\n",
        "    matrix = diff_patient[i]\n",
        "    # Check if the matrix is equal to its transpose within a tolerance\n",
        "    # Using a tolerance is important for floating-point numbers\n",
        "    if np.allclose(matrix, matrix.T):\n",
        "        symmetric_count += 1\n",
        "    else:\n",
        "        nonsymmetric_indices.append(i)\n",
        "\n",
        "print(f\"\\nTotal number of matrices: {num_matrices}\")\n",
        "print(f\"Number of symmetric matrices: {symmetric_count}\")\n",
        "print(f\"Number of non-symmetric matrices: {num_matrices - symmetric_count}\")\n",
        "\n",
        "if nonsymmetric_indices:\n",
        "    print(f\"Indices of non-symmetric matrices (first 10): {nonsymmetric_indices[:10]}{'...' if len(nonsymmetric_indices) > 10 else ''}\")\n",
        "else:\n",
        "    print(\"All matrices are symmetric.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGIzwDKMFO37",
        "outputId": "31a3f19b-22ed-4117-a76b-0aa6733a1c8b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numerical range of diff_patient.npy: [-0.9856339190451243, 1.0143660809548758]\n",
            "\n",
            "Total number of matrices: 335\n",
            "Number of symmetric matrices: 335\n",
            "Number of non-symmetric matrices: 0\n",
            "All matrices are symmetric.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import NNConv, TopKPooling, global_mean_pool\n",
        "from torch_geometric.data import Data # Import Data for the inference encoder output\n",
        "\n",
        "# --- Redefined Encoder and Decoder for Latent Graph Structure (approx 16 nodes) ---\n",
        "\n",
        "class GraphVAE_Encoder_V2(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, pooled_ratio):\n",
        "        super().__init__()\n",
        "        nn1_enc = nn.Sequential(nn.Linear(1, 32), nn.ReLU(), nn.Linear(32, in_channels * hidden_channels))\n",
        "        self.conv1 = NNConv(in_channels, hidden_channels, nn1_enc, aggr='mean')\n",
        "\n",
        "        # Pool to approx 16 nodes\n",
        "        # ratio=16/64 = 0.25\n",
        "        self.pool = TopKPooling(hidden_channels, ratio=pooled_ratio)\n",
        "\n",
        "        nn2_enc = nn.Sequential(nn.Linear(1, 32), nn.ReLU(), nn.Linear(32, hidden_channels * hidden_channels))\n",
        "        self.conv2 = NNConv(hidden_channels, hidden_channels, nn2_enc, aggr='mean')\n",
        "\n",
        "        # The latent representation will be the features and structure of the pooled graph.\n",
        "        # We still need mu and logvar for the VAE framework, traditionally applied to a continuous vector space.\n",
        "        # For Graph VAEs, sometimes mu and logvar are predicted per node feature of the pooled graph.\n",
        "        self.lin_mu = nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.lin_logvar = nn.Linear(hidden_channels, hidden_channels)\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch):\n",
        "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
        "        # The first pooling step is essential for reducing the number of nodes\n",
        "        x_pooled, edge_index_pooled, edge_attr_pooled, batch_pooled, original_node_indices, _ = self.pool(x, edge_index, edge_attr, batch=batch)\n",
        "\n",
        "        # Apply another convolution on the pooled graph\n",
        "        x_pooled = F.relu(self.conv2(x_pooled, edge_index_pooled, edge_attr_pooled))\n",
        "\n",
        "        # Predict mu and logvar for the pooled node features\n",
        "        mu = self.lin_mu(x_pooled)\n",
        "        logvar = self.lin_logvar(x_pooled)\n",
        "\n",
        "        # Reparameterization trick on pooled node features\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        z_node_features = mu + eps * std\n",
        "\n",
        "        # We return the components of the latent graph structure (features, edges, batch, original indices)\n",
        "        # and the VAE parameters (mu, logvar) for the loss calculation.\n",
        "        return z_node_features, edge_index_pooled, edge_attr_pooled, batch_pooled, original_node_indices, mu, logvar\n",
        "\n",
        "\n",
        "class GraphVAE_Decoder_V2(nn.Module):\n",
        "    def __init__(self, latent_channels, hidden_channels, original_num_nodes):\n",
        "        super().__init__()\n",
        "        self.original_num_nodes = original_num_nodes\n",
        "\n",
        "        # The decoder takes the latent graph node features (~16 nodes) and reconstructs the 64x64 graph.\n",
        "        # This decoder uses global pooling on the latent node features and then dense layers.\n",
        "        self.global_pool = global_mean_pool\n",
        "        # Input to the dense layers will be the pooled latent node features (size latent_channels)\n",
        "        self.fc_recon = nn.Sequential(\n",
        "            nn.Linear(latent_channels, hidden_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_channels, original_num_nodes * original_num_nodes)\n",
        "        )\n",
        "\n",
        "    def forward(self, z_node_features, batch_pooled): # Only z_node_features and batch_pooled are used in this decoder's forward\n",
        "        # Global pool the latent node features\n",
        "        pooled_latent_features = self.global_pool(z_node_features, batch_pooled)\n",
        "\n",
        "        # Predict the flattened 64x64 adjacency matrix\n",
        "        recon_flat = self.fc_recon(pooled_latent_features)\n",
        "\n",
        "        # Reshape into a batch of 64x64 matrices\n",
        "        recon_adj = recon_flat.view(-1, self.original_num_nodes, self.original_num_nodes)\n",
        "        recon_adj = 0.5 * (recon_adj + recon_adj.transpose(1, 2)) # Symmetrize\n",
        "\n",
        "        return recon_adj\n",
        "\n",
        "# --- Full Graph-to-Graph VAE (Approximation) ---\n",
        "class GraphToGraphVAE(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, pooled_ratio, original_num_nodes):\n",
        "        super().__init__()\n",
        "        # The encoder outputs pooled node features and the pooled graph structure + VAE params\n",
        "        self.encoder = GraphVAE_Encoder_V2(in_channels, hidden_channels, pooled_ratio)\n",
        "        # The decoder takes the pooled node features (after reparametrization) and reconstructs the original matrix\n",
        "        self.decoder = GraphVAE_Decoder_V2(hidden_channels, hidden_channels, original_num_nodes) # Latent channels are hidden_channels from encoder output\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch):\n",
        "        # Pass through encoder\n",
        "        # The encoder now returns components of the pooled graph + mu/logvar\n",
        "        z_node_features, edge_index_pooled, edge_attr_pooled, batch_pooled, original_node_indices, mu, logvar = self.encoder(x, edge_index, edge_attr, batch)\n",
        "\n",
        "        # Pass latent node features through the decoder to reconstruct the original adjacency matrix\n",
        "        # The decoder uses the features from the pooled graph, but reconstructs the original size graph.\n",
        "        # We don't pass the latent edge_index/attr/batch to this specific decoder structure,\n",
        "        # as it uses global pooling on the node features.\n",
        "        recon_adj = self.decoder(z_node_features, batch_pooled) # Only z_node_features and batch_pooled are used\n",
        "\n",
        "        # Return the reconstructed adjacency matrix and the VAE parameters (mu, logvar)\n",
        "        return recon_adj, mu, logvar\n",
        "\n",
        "# --- GraphVAE_Encoder for Inference ---\n",
        "# This class inherits from GraphVAE_Encoder_V2 and modifies the forward pass\n",
        "# to return the latent graph Data object and the original node indices.\n",
        "class GraphVAE_Encoder_Inference(GraphVAE_Encoder_V2):\n",
        "     def forward(self, x, edge_index, edge_attr, batch):\n",
        "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
        "        # Apply pooling to get the smaller graph structure and original node indices\n",
        "        x_pooled, edge_index_pooled, edge_attr_pooled, batch_pooled, original_node_indices, _ = self.pool(x, edge_index, edge_attr, batch=batch)\n",
        "\n",
        "        # Apply the second convolution on the pooled graph features\n",
        "        x_pooled = F.relu(self.conv2(x_pooled, edge_index_pooled, edge_attr_pooled))\n",
        "\n",
        "        # Create a Data object for the latent graph\n",
        "        # Note: This assumes the batch size is 1 during inference when creating a single Data object per graph.\n",
        "        # If batching is needed for inference, this part would need modification.\n",
        "        latent_graph_data = Data(x=x_pooled, edge_index=edge_index_pooled, edge_attr=edge_attr_pooled, batch=batch_pooled)\n",
        "\n",
        "        # Return the latent graph Data object and the original node indices that were pooled\n",
        "        return latent_graph_data, original_node_indices\n",
        "\n",
        "# --- VAE Loss Function ---\n",
        "def loss_function(recon_adj, original_adj, mu, logvar):\n",
        "    # MSE reconstruction loss (symmetric adjacency reconstruction)\n",
        "    # Ensure shapes match and handle potential padding in original_adj\n",
        "    # original_adj should be batch_size x 64 x 64\n",
        "    # recon_adj is batch_size x 64 x 64 from the decoder\n",
        "    recon_loss = F.mse_loss(recon_adj, original_adj, reduction='mean')\n",
        "\n",
        "    # KL divergence for VAE\n",
        "    # KL divergence is calculated per parameter dimension (hidden_channels in mu/logvar)\n",
        "    # torch.mean will average over the batch and the feature dimensions\n",
        "    kl_div = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return recon_loss + kl_div, recon_loss, kl_div"
      ],
      "metadata": {
        "id": "N8gNkCHuFfG6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(123) # It could be any seed. I did not save the seed that provided the current result.\n",
        "import torch.optim as optim # Import optim for optimizer\n",
        "\n",
        "# Ensure the model and optimizer are defined and moved to the device\n",
        "model_graph_vae = GraphToGraphVAE(in_channels=64, hidden_channels=128, pooled_ratio=0.25, original_num_nodes=64).to(device)\n",
        "optimizer_graph_vae = optim.Adam(model_graph_vae.parameters(), lr=1e-3)\n",
        "# Assume these are already defined and on the correct device from previous steps if continuing a session.\n",
        "# If not, uncomment and define them here.\n",
        "\n",
        "epochs = 50 # Number of training epochs\n",
        "\n",
        "# Set the model to training mode\n",
        "model_graph_vae.train()\n",
        "\n",
        "print(f\"Starting training for {epochs} epochs...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    total_recon = 0\n",
        "    total_kl = 0\n",
        "\n",
        "    # Iterate over batches from the DataLoader\n",
        "    for batch in loader:\n",
        "        # Move batch data to the same device as the model\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        optimizer_graph_vae.zero_grad()\n",
        "\n",
        "        # Forward pass through the Graph-to-Graph VAE\n",
        "        # The model forward returns recon_adj, mu, logvar\n",
        "        recon_adj, mu, logvar = model_graph_vae(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
        "\n",
        "        # Prepare the original adjacency matrices from the batch for loss calculation\n",
        "        # The batch object contains individual graphs. We need to extract their original\n",
        "        # adjacency matrices and stack them into a batch tensor.\n",
        "        original_adj_list = []\n",
        "        # The batch object can be iterated over to get individual Data objects\n",
        "        # Or we can reconstruct the original matrices from edge_index and edge_attr\n",
        "        # using the batch index to separate graphs. Let's reconstruct from batch.\n",
        "        # Assuming original_num_nodes=64 for all graphs\n",
        "\n",
        "        # Reconstruct adjacency matrices from the batch using batch index\n",
        "        num_graphs_in_batch = batch.num_graphs # Number of graphs in the current batch\n",
        "        original_adj = torch.zeros(num_graphs_in_batch, 64, 64, device=device)\n",
        "\n",
        "        # Iterate through each graph in the batch\n",
        "        for i in range(num_graphs_in_batch):\n",
        "            # Get the mask for nodes belonging to the i-th graph in the batch\n",
        "            node_mask = batch.batch == i\n",
        "            # Get the indices of nodes belonging to the i-th graph in the batch\n",
        "            node_indices_in_batch = torch.where(node_mask)[0]\n",
        "\n",
        "            if len(node_indices_in_batch) == 0:\n",
        "                 continue # Skip if no nodes in this graph (shouldn't happen with valid data)\n",
        "\n",
        "            # Get the edge indices and edge attributes for the i-th graph\n",
        "            # Need to filter edges based on whether both source and target nodes are in the current graph\n",
        "            edge_mask_i = (batch.edge_index[0] >= node_indices_in_batch.min()) & \\\n",
        "                          (batch.edge_index[0] <= node_indices_in_batch.max()) & \\\n",
        "                          (batch.edge_index[1] >= node_indices_in_batch.min()) & \\\n",
        "                          (batch.edge_index[1] <= node_indices_in_batch.max())\n",
        "\n",
        "            edge_index_i = batch.edge_index[:, edge_mask_i]\n",
        "            edge_attr_i = batch.edge_attr[edge_mask_i].squeeze() # Use squeeze to handle shape [num_edges, 1]\n",
        "\n",
        "            # Re-index edge_index to be relative to the start of the current graph's nodes in the batch\n",
        "            # This is not needed if we directly populate the 64x64 matrix for each graph\n",
        "            # using the original node indices within the batch's x tensor.\n",
        "\n",
        "            # Populate the 64x64 adjacency matrix for the i-th graph\n",
        "            # The node indices in batch.edge_index are relative to the concatenated batch,\n",
        "            # but they correspond to the original node indices if x is identity matrix and nodes are ordered.\n",
        "            # Assuming the node ordering in the batch corresponds to the original node ordering within each graph's 64 nodes.\n",
        "            # A simpler way is to iterate through the original `graphs` list and get the original matrices.\n",
        "            # However, the DataLoader batches these, so we need to align the reconstructed batch with the original batch.\n",
        "\n",
        "            # Let's go back to extracting from the original Data objects based on the batch structure.\n",
        "            # The `batch` object provides `to_data_list()` which splits the batch back into individual Data objects.\n",
        "            original_data_list = batch.to_data_list()\n",
        "            for j, data in enumerate(original_data_list):\n",
        "                num_nodes_graph = data.num_nodes # Should be 64\n",
        "                edge_index_graph = data.edge_index.to(device)\n",
        "                # Ensure edge_attr_graph is correctly shaped for populating the matrix\n",
        "                edge_attr_graph = data.edge_attr.squeeze().to(device) # Remove dimension 1 if it exists\n",
        "\n",
        "                adj_graph = torch.zeros(num_nodes_graph, num_nodes_graph, device=device)\n",
        "\n",
        "                # Handle cases where edge_attr_graph might be empty or scalar\n",
        "                if edge_attr_graph.numel() > 0:\n",
        "                     # Need to handle cases where edge_attr_graph might be a scalar if only one edge\n",
        "                     if edge_attr_graph.dim() == 0:\n",
        "                          # If scalar, ensure edge_index_graph has correct shape [2, 1]\n",
        "                          if edge_index_graph.size(1) == 1:\n",
        "                               adj_graph[edge_index_graph[0, 0], edge_index_graph[1, 0]] = edge_attr_graph\n",
        "                          # If edge_index_graph is [2, 0] (no edges) and edge_attr_graph is scalar (shouldn't happen), do nothing.\n",
        "                     else:\n",
        "                          # If edge_attr_graph is a tensor, ensure its size matches the number of edges\n",
        "                          if edge_attr_graph.size(0) == edge_index_graph.size(1):\n",
        "                               adj_graph[edge_index_graph[0], edge_index_graph[1]] = edge_attr_graph\n",
        "                          # else: Handle mismatch if necessary, maybe log a warning.\n",
        "\n",
        "                adj_graph = 0.5 * (adj_graph + adj_graph.transpose(0, 1)) # Symmetrize\n",
        "                # original_adj_list.append(adj_graph) # Append to a list first\n",
        "\n",
        "                # Place this graph's adjacency matrix into the corresponding slot in the batch tensor\n",
        "                # Assuming the order in original_data_list matches the order in the reconstructed batch\n",
        "                original_adj[j] = adj_graph # Populate the pre-allocated tensor\n",
        "\n",
        "        # Stack the individual adjacency matrices into a batch tensor (if using list append)\n",
        "        # This stacking is not needed if we populate `original_adj` tensor directly as above.\n",
        "        # original_adj = torch.stack(original_adj_list).to(device)\n",
        "\n",
        "\n",
        "        # Compute loss using the reconstructed batch of original adjacency matrices\n",
        "        loss, recon, kl = loss_function(recon_adj, original_adj, mu, logvar)\n",
        "        loss.backward()\n",
        "        optimizer_graph_vae.step()\n",
        "\n",
        "        total_loss += loss.item() * num_graphs_in_batch # Accumulate loss weighted by batch size\n",
        "        total_recon += recon.item() * num_graphs_in_batch\n",
        "        total_kl += kl.item() * num_graphs_in_batch\n",
        "\n",
        "    # Average the total loss over all graphs\n",
        "    avg_loss = total_loss / len(graphs)\n",
        "    avg_recon = total_recon / len(graphs)\n",
        "    avg_kl = total_kl / len(graphs)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:03d} | Avg Total Loss: {avg_loss:.6f} | Avg Recon: {avg_recon:.6f} | Avg KL: {avg_kl:.6f}\")\n",
        "\n",
        "print(\"Training finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR6tElBtFlbc",
        "outputId": "58df31d5-7799-4ceb-9677-95dc44c7a4aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for 50 epochs...\n",
            "Epoch 001 | Avg Total Loss: 0.003010 | Avg Recon: 0.001992 | Avg KL: 0.001018\n",
            "Epoch 002 | Avg Total Loss: 0.001153 | Avg Recon: 0.001039 | Avg KL: 0.000115\n",
            "Epoch 003 | Avg Total Loss: 0.000810 | Avg Recon: 0.000769 | Avg KL: 0.000041\n",
            "Epoch 004 | Avg Total Loss: 0.000634 | Avg Recon: 0.000619 | Avg KL: 0.000015\n",
            "Epoch 005 | Avg Total Loss: 0.000511 | Avg Recon: 0.000505 | Avg KL: 0.000006\n",
            "Epoch 006 | Avg Total Loss: 0.000430 | Avg Recon: 0.000427 | Avg KL: 0.000003\n",
            "Epoch 007 | Avg Total Loss: 0.000376 | Avg Recon: 0.000374 | Avg KL: 0.000003\n",
            "Epoch 008 | Avg Total Loss: 0.000339 | Avg Recon: 0.000337 | Avg KL: 0.000002\n",
            "Epoch 009 | Avg Total Loss: 0.000306 | Avg Recon: 0.000304 | Avg KL: 0.000002\n",
            "Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000283 | Avg KL: 0.000001\n",
            "Epoch 011 | Avg Total Loss: 0.000268 | Avg Recon: 0.000266 | Avg KL: 0.000001\n",
            "Epoch 012 | Avg Total Loss: 0.000250 | Avg Recon: 0.000249 | Avg KL: 0.000001\n",
            "Epoch 013 | Avg Total Loss: 0.000241 | Avg Recon: 0.000240 | Avg KL: 0.000001\n",
            "Epoch 014 | Avg Total Loss: 0.000231 | Avg Recon: 0.000231 | Avg KL: 0.000001\n",
            "Epoch 015 | Avg Total Loss: 0.000222 | Avg Recon: 0.000221 | Avg KL: 0.000001\n",
            "Epoch 016 | Avg Total Loss: 0.000216 | Avg Recon: 0.000215 | Avg KL: 0.000001\n",
            "Epoch 017 | Avg Total Loss: 0.000211 | Avg Recon: 0.000210 | Avg KL: 0.000001\n",
            "Epoch 018 | Avg Total Loss: 0.000206 | Avg Recon: 0.000205 | Avg KL: 0.000001\n",
            "Epoch 019 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "Epoch 021 | Avg Total Loss: 0.000195 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "Epoch 022 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "Epoch 023 | Avg Total Loss: 0.000189 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "Epoch 024 | Avg Total Loss: 0.000187 | Avg Recon: 0.000186 | Avg KL: 0.000001\n",
            "Epoch 025 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "Epoch 026 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "Epoch 027 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "Epoch 028 | Avg Total Loss: 0.000181 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "Epoch 029 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000001\n",
            "Epoch 031 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000001\n",
            "Epoch 032 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Epoch 033 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Epoch 034 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Epoch 035 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Epoch 036 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Epoch 037 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000001\n",
            "Epoch 038 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Epoch 039 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Epoch 041 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Epoch 042 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Epoch 043 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Epoch 044 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Epoch 045 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Epoch 046 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Epoch 047 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Epoch 048 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Epoch 049 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000001\n",
            "Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # Ensure torch is imported\n",
        "from torch_geometric.data import Data # Ensure Data is imported\n",
        "\n",
        "# Assuming model_graph_vae has been trained and is on the correct device\n",
        "# Ensure you have run the cell that trains model_graph_vae before this cell.\n",
        "# model_graph_vae.to(device) # Ensure it's on the device if you didn't do this after loading\n",
        "\n",
        "# Create an instance of the inference encoder and load the trained weights\n",
        "# Ensure GraphVAE_Encoder_Inference is defined by running the previous definition cell.\n",
        "model_encoder_inference = GraphVAE_Encoder_Inference(\n",
        "    in_channels=64,\n",
        "    hidden_channels=128,\n",
        "    pooled_ratio=0.25 # Use the same ratio as during training\n",
        ").to(device)\n",
        "\n",
        "# Load the state dictionary from the trained model's encoder\n",
        "# Ensure model_graph_vae exists and is trained before loading state_dict\n",
        "model_encoder_inference.load_state_dict(model_graph_vae.encoder.state_dict())\n",
        "\n",
        "# Set the encoder to evaluation mode\n",
        "model_encoder_inference.eval()\n",
        "\n",
        "# List to store the latent graph data objects and their corresponding pooled indices\n",
        "# Each element will be a tuple: (latent_graph_data, pooled_indices)\n",
        "latent_graphs_list = []\n",
        "\n",
        "# Process each graph individually to get its latent representation\n",
        "# We use no_grad() as we are not training\n",
        "with torch.no_grad():\n",
        "    for graph in graphs: # Iterate through your list of original Data objects\n",
        "        # Move the single graph to the device\n",
        "        single_graph_on_device = graph.to(device)\n",
        "\n",
        "        # Create a batch tensor for a single graph.\n",
        "        # It should have the same number of elements as the number of nodes in the graph,\n",
        "        # and all elements should be 0 to indicate they belong to the same batch (batch 0).\n",
        "        batch_tensor = torch.zeros(single_graph_on_device.num_nodes, dtype=torch.long, device=device)\n",
        "\n",
        "        # Pass the single graph through the inference encoder\n",
        "        # GraphVAE_Encoder_Inference is designed to return 2 values:\n",
        "        # latent_graph_data (a Data object for the pooled graph) and pooled_indices (original node indices)\n",
        "        latent_graph_data, pooled_indices = model_encoder_inference(\n",
        "            single_graph_on_device.x,\n",
        "            single_graph_on_device.edge_index,\n",
        "            single_graph_on_device.edge_attr,\n",
        "            batch_tensor\n",
        "        )\n",
        "\n",
        "        # Append the resulting latent graph Data object AND the pooled indices to the list as a tuple\n",
        "        # Move both to CPU before storing if needed for later processing or saving\n",
        "        latent_graphs_list.append((latent_graph_data.cpu(), pooled_indices.cpu()))\n",
        "\n",
        "\n",
        "print(f\"Obtained {len(latent_graphs_list)} latent graphs and their pooled indices.\")\n",
        "\n",
        "# You can inspect the first latent graph and its indices\n",
        "if len(latent_graphs_list) > 0:\n",
        "    first_latent_graph_data, first_pooled_indices = latent_graphs_list[0]\n",
        "    print(f\"First latent graph nodes: {first_latent_graph_data.num_nodes}\")\n",
        "    print(f\"First latent graph edges: {first_latent_graph_data.num_edges}\")\n",
        "    print(f\"First pooled node indices: {first_pooled_indices}\")\n",
        "    # You can convert the latent graph back to an adjacency matrix if needed:\n",
        "    # Note: the size will be approximately 16x16, but can vary slightly due to TopKPooling\n",
        "    latent_adj = torch.zeros(first_latent_graph_data.num_nodes, first_latent_graph_data.num_nodes)\n",
        "    # Need to handle scalar edge_attr if there's only one edge in the latent graph\n",
        "    if hasattr(first_latent_graph_data, 'edge_attr') and first_latent_graph_data.edge_attr is not None and first_latent_graph_data.edge_attr.numel() > 0:\n",
        "         edge_attr_squeeze = first_latent_graph_data.edge_attr.squeeze()\n",
        "         if edge_attr_squeeze.dim() == 0:\n",
        "              # Handle scalar edge_attr\n",
        "              if first_latent_graph_data.edge_index.size(1) == 1:\n",
        "                   latent_adj[first_latent_graph_data.edge_index[0, 0], first_latent_graph_data.edge_index[1, 0]] = edge_attr_squeeze\n",
        "         else:\n",
        "              # Handle tensor edge_attr\n",
        "              if edge_attr_squeeze.size(0) == first_latent_graph_data.edge_index.size(1):\n",
        "                   latent_adj[first_latent_graph_data.edge_index[0], first_latent_graph_data.edge_index[1]] = edge_attr_squeeze\n",
        "\n",
        "\n",
        "    print(f\"First latent adjacency matrix shape: {latent_adj.shape}\")\n",
        "\n",
        "# latent_graphs_list is now populated and ready for the next steps (saving indices and matrices)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KYwBq2eFpWI",
        "outputId": "5104c216-e454-4cfb-d4dd-ad7aa50163a4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtained 335 latent graphs and their pooled indices.\n",
            "First latent graph nodes: 16\n",
            "First latent graph edges: 166\n",
            "First pooled node indices: tensor([23, 12,  0, 36, 51,  1,  5, 61, 18, 13,  6, 25, 57, 49, 35, 20])\n",
            "First latent adjacency matrix shape: torch.Size([16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latent_graphs_list[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQC1oUOYIbgP",
        "outputId": "6b9a8bd2-c1b7-4816-bc42-4e554a625b13"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Data(x=[16, 128], edge_index=[2, 200], edge_attr=[200, 1], batch=[16]),\n",
              " tensor([23, 17, 34,  8,  2, 37, 31,  7, 27, 32,  5, 25, 15, 16, 11, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uZoc_aJUIgRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e7ce5e4"
      },
      "source": [
        "# Task\n",
        "Perform bootstrapped linear regression to identify significant latent graph edges associated with the 'IT' vector. This involves 10 bootstrap iterations, converting latent graph representations into 16x16 adjacency matrices, averaging these matrices, and then performing univariate linear regression for each unique edge. Finally, report edges with a p-value less than 0.05."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6cb848e"
      },
      "source": [
        "# Task\n",
        "Perform bootstrapped linear regression to identify significant latent graph edges associated with the 'IT' vector. This involves 10 bootstrap iterations, converting latent graph representations into 16x16 adjacency matrices, averaging these matrices, and then performing univariate linear regression for each unique edge. Finally, report edges with a p-value less than 0.05.\n",
        "\n",
        "```python\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Define bootstrapping and training parameters\n",
        "num_bootstrap_iterations = 10\n",
        "bootstrap_epochs = 50 # Keeping 50 for now, can reduce if training time is too long\n",
        "\n",
        "# List to store the sets of latent adjacency matrices from each bootstrap iteration\n",
        "# Each element will be a tensor of shape (num_original_graphs, ~16, ~16)\n",
        "all_bootstrap_latent_adj_matrices = []\n",
        "\n",
        "num_original_graphs = len(graphs) # 335\n",
        "\n",
        "# Helper function to convert a latent Data object into an adjacency matrix\n",
        "def latent_data_to_adj_matrix(latent_data):\n",
        "    num_nodes = latent_data.num_nodes # This should be around 16\n",
        "    latent_adj = torch.zeros(num_nodes, num_nodes, device=latent_data.x.device)\n",
        "\n",
        "    if hasattr(latent_data, 'edge_attr') and latent_data.edge_attr is not None and latent_data.edge_attr.numel() > 0:\n",
        "        edge_attr_squeeze = latent_data.edge_attr.squeeze()\n",
        "        edge_index = latent_data.edge_index\n",
        "\n",
        "        if edge_attr_squeeze.dim() == 0 and edge_index.size(1) == 1:\n",
        "            # Handle scalar edge_attr for a single edge\n",
        "            latent_adj[edge_index[0, 0], edge_index[1, 0]] = edge_attr_squeeze\n",
        "        elif edge_attr_squeeze.dim() > 0 and edge_attr_squeeze.size(0) == edge_index.size(1):\n",
        "            # Handle tensor edge_attr for multiple edges\n",
        "            latent_adj[edge_index[0], edge_index[1]] = edge_attr_squeeze\n",
        "        # No else needed, if dimensions don't match or no edges, matrix remains zeros\n",
        "\n",
        "    # Ensure symmetry\n",
        "    latent_adj = 0.5 * (latent_adj + latent_adj.transpose(0, 1))\n",
        "    return latent_adj.cpu() # Return to CPU\n",
        "\n",
        "\n",
        "# Bootstrap Loop\n",
        "for bootstrap_idx in range(num_bootstrap_iterations):\n",
        "    print(f\"\\n--- Bootstrap Iteration {bootstrap_idx + 1}/{num_bootstrap_iterations} ---\")\n",
        "\n",
        "    # 1. Sample Data: Randomly sample num_original_graphs indices with replacement\n",
        "    sampled_indices = torch.randint(0, num_original_graphs, (num_original_graphs,), replacement=True).tolist()\n",
        "    bootstrapped_graphs = [graphs[i] for i in sampled_indices]\n",
        "    # IT_tensor is not directly used for HVAE training, but if it were, we'd sample it here:\n",
        "    # bootstrapped_IT_tensor = IT_tensor[sampled_indices]\n",
        "\n",
        "    # 2. Prepare Bootstrapped DataLoader\n",
        "    bootstrapped_loader = DataLoader(bootstrapped_graphs, batch_size=32, shuffle=True)\n",
        "\n",
        "    # 3. Initialize and Train HVAE\n",
        "    # Re-initialize model and optimizer for each bootstrap iteration\n",
        "    model_graph_vae_bootstrap = GraphToGraphVAE(in_channels=64, hidden_channels=128, pooled_ratio=0.25, original_num_nodes=64).to(device)\n",
        "    optimizer_graph_vae_bootstrap = optim.Adam(model_graph_vae_bootstrap.parameters(), lr=1e-3)\n",
        "\n",
        "    model_graph_vae_bootstrap.train()\n",
        "    print(f\"Training HVAE for {bootstrap_epochs} epochs on bootstrapped data...\")\n",
        "\n",
        "    for epoch in range(bootstrap_epochs):\n",
        "        total_loss = 0\n",
        "        total_recon = 0\n",
        "        total_kl = 0\n",
        "        num_graphs_processed = 0\n",
        "\n",
        "        for batch in bootstrapped_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer_graph_vae_bootstrap.zero_grad()\n",
        "            recon_adj, mu, logvar = model_graph_vae_bootstrap(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
        "\n",
        "            original_adj = torch.zeros(batch.num_graphs, 64, 64, device=device)\n",
        "            original_data_list = batch.to_data_list()\n",
        "            for j, data in enumerate(original_data_list):\n",
        "                adj_graph = torch.zeros(data.num_nodes, data.num_nodes, device=device)\n",
        "                if data.edge_attr is not None and data.edge_attr.numel() > 0:\n",
        "                    edge_attr_squeeze = data.edge_attr.squeeze()\n",
        "                    if edge_attr_squeeze.dim() == 0 and data.edge_index.size(1) == 1:\n",
        "                        adj_graph[data.edge_index[0, 0], data.edge_index[1, 0]] = edge_attr_squeeze\n",
        "                    elif edge_attr_squeeze.dim() > 0 and edge_attr_squeeze.size(0) == data.edge_index.size(1):\n",
        "                        adj_graph[data.edge_index[0], data.edge_index[1]] = edge_attr_squeeze\n",
        "                adj_graph = 0.5 * (adj_graph + adj_graph.transpose(0, 1))\n",
        "                original_adj[j] = adj_graph\n",
        "\n",
        "            loss, recon, kl = loss_function(recon_adj, original_adj, mu, logvar)\n",
        "            loss.backward()\n",
        "            optimizer_graph_vae_bootstrap.step()\n",
        "\n",
        "            total_loss += loss.item() * batch.num_graphs\n",
        "            total_recon += recon.item() * batch.num_graphs\n",
        "            total_kl += kl.item() * batch.num_graphs\n",
        "            num_graphs_processed += batch.num_graphs\n",
        "\n",
        "        # Average over actual number of graphs processed in the bootstrapped loader\n",
        "        avg_loss = total_loss / num_graphs_processed if num_graphs_processed > 0 else 0\n",
        "        avg_recon = total_recon / num_graphs_processed if num_graphs_processed > 0 else 0\n",
        "        avg_kl = total_kl / num_graphs_processed if num_graphs_processed > 0 else 0\n",
        "\n",
        "        # Print progress less frequently for bootstrap training\n",
        "        if (epoch + 1) % 10 == 0 or epoch == 0 or epoch == bootstrap_epochs - 1:\n",
        "            print(f\"  Epoch {epoch+1:03d} | Avg Total Loss: {avg_loss:.6f} | Avg Recon: {avg_recon:.6f} | Avg KL: {avg_kl:.6f}\")\n",
        "\n",
        "\n",
        "    # 4. Extract Latent Representations for ALL Original Graphs (not just bootstrapped sample)\n",
        "    # Use the newly trained model_graph_vae_bootstrap's encoder\n",
        "    model_encoder_inference_bootstrap = GraphVAE_Encoder_Inference(\n",
        "        in_channels=64,\n",
        "        hidden_channels=128,\n",
        "        pooled_ratio=0.25\n",
        "    ).to(device)\n",
        "    model_encoder_inference_bootstrap.load_state_dict(model_graph_vae_bootstrap.encoder.state_dict())\n",
        "    model_encoder_inference_bootstrap.eval()\n",
        "\n",
        "    current_bootstrap_latent_graphs_data_list = []\n",
        "    with torch.no_grad():\n",
        "        for graph in graphs: # Process ALL original graphs\n",
        "            single_graph_on_device = graph.to(device)\n",
        "            batch_tensor = torch.zeros(single_graph_on_device.num_nodes, dtype=torch.long, device=device)\n",
        "            latent_graph_data, pooled_indices = model_encoder_inference_bootstrap(\n",
        "                single_graph_on_device.x,\n",
        "                single_graph_on_device.edge_index,\n",
        "                single_graph_on_device.edge_attr,\n",
        "                batch_tensor\n",
        "            )\n",
        "            current_bootstrap_latent_graphs_data_list.append((latent_graph_data.cpu(), pooled_indices.cpu()))\n",
        "\n",
        "    # 5. Convert to Latent Adjacency Matrices (approx 16x16)\n",
        "    # The latent_data_to_adj_matrix function handles converting the Data object to an adj matrix\n",
        "    current_bootstrap_latent_adj_matrices = [\n",
        "        latent_data_to_adj_matrix(latent_data)\n",
        "        for latent_data, _ in current_bootstrap_latent_graphs_data_list\n",
        "    ]\n",
        "\n",
        "    all_bootstrap_latent_adj_matrices.append(torch.stack(current_bootstrap_latent_adj_matrices))\n",
        "    print(f\"Finished bootstrap iteration {bootstrap_idx + 1}. Extracted latent matrices for all {len(graphs)} original graphs.\")\n",
        "\n",
        "# Convert the list of tensors to a single tensor for easier averaging\n",
        "# Shape: (num_bootstrap_iterations, num_original_graphs, 16, 16)\n",
        "all_bootstrap_latent_adj_matrices_tensor = torch.stack(all_bootstrap_latent_adj_matrices)\n",
        "\n",
        "# Average Latent Adjacency Matrices\n",
        "# Resulting shape: (num_original_graphs, 16, 16)\n",
        "averaged_latent_adj_matrices = torch.mean(all_bootstrap_latent_adj_matrices_tensor, dim=0)\n",
        "\n",
        "print(f\"\\nAveraged {num_bootstrap_iterations} sets of latent adjacency matrices. Resulting shape: {averaged_latent_adj_matrices.shape}\")\n",
        "\n",
        "\n",
        "# Perform Univariate Linear Regression\n",
        "# We need statsmodels for regression\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "# The latent adjacency matrices are 16x16. We need to iterate through unique edges.\n",
        "# For a symmetric matrix, we consider the upper triangle (excluding diagonal).\n",
        "latent_dim = averaged_latent_adj_matrices.shape[1] # Should be 16\n",
        "\n",
        "regression_results = [] # Store p-value and coefficient for each edge\n",
        "\n",
        "print(\"\\nPerforming univariate linear regression for each latent edge...\")\n",
        "\n",
        "# Iterate through upper triangle of the latent adjacency matrix\n",
        "for i in range(latent_dim):\n",
        "    for j in range(i + 1, latent_dim): # i+1 to exclude diagonal and avoid duplicates\n",
        "        # Extract edge values for the current edge (i, j) across all patients\n",
        "        edge_values = averaged_latent_adj_matrices[:, i, j] # Shape: (335,)\n",
        "\n",
        "        # Convert to numpy for statsmodels\n",
        "        y = edge_values.numpy()\n",
        "        X = IT_tensor.numpy() # Independent variable (IT scores)\n",
        "\n",
        "        # Add a constant to the independent variable for intercept calculation\n",
        "        X = sm.add_constant(X)\n",
        "\n",
        "        # Perform OLS regression\n",
        "        model = sm.OLS(y, X)\n",
        "        results = model.fit()\n",
        "\n",
        "        # Store p-value and coefficient for the IT variable (index 1 after constant)\n",
        "        p_value = results.pvalues[1]\n",
        "        coefficient = results.params[1]\n",
        "\n",
        "        regression_results.append({\n",
        "            'node_i': i,\n",
        "            'node_j': j,\n",
        "            'p_value': p_value,\n",
        "            'coefficient': coefficient\n",
        "        })\n",
        "\n",
        "# Report Significant Edges\n",
        "significant_edges = []\n",
        "alpha = 0.05\n",
        "\n",
        "print(f\"\\n--- Significant Latent Edges (p-value < {alpha}) ---\")\n",
        "for res in regression_results:\n",
        "    if res['p_value'] < alpha:\n",
        "        significant_edges.append(res)\n",
        "        print(f\"Edge ({res['node_i']}, {res['node_j']}): \"\n",
        "              f\"P-value = {res['p_value']:.4f}, Coefficient = {res['coefficient']:.4f}\")\n",
        "\n",
        "if not significant_edges:\n",
        "    print(\"No significant latent edges found at the specified alpha level.\")\n",
        "else:\n",
        "    print(f\"\\nFound {len(significant_edges)} significant latent edges.\")\n",
        "\n",
        "# Final Task Summary\n",
        "print(\"\\n--- Summary of Findings ---\")\n",
        "print(\"Bootstrapped HVAE training was performed to derive stable latent graph representations.\")\n",
        "print(f\"Across {num_bootstrap_iterations} iterations, HVAE models were trained on resampled data.\")\n",
        "print(f\"The latent adjacency matrices (approximately {latent_dim}x{latent_dim}) for all original graphs were averaged.\")\n",
        "print(\"Univariate linear regression was then performed for each unique edge in these averaged latent matrices, \"\n",
        "      \"testing its association with the 'IT' vector.\")\n",
        "\n",
        "if significant_edges:\n",
        "    print(f\"We identified {len(significant_edges)} latent graph edges that are significantly associated with the 'IT' vector (p < {alpha}).\")\n",
        "    print(\"These significant edges and their corresponding p-values and coefficients are listed above.\")\n",
        "    print(\"Further analysis could involve visualizing these nodes on a 16-node graph to understand \"\n",
        "          \"which latent structural connections are relevant to the 'IT' variable.\")\n",
        "else:\n",
        "    print(\"No significant associations were found between individual latent graph edges and the 'IT' vector \"\n",
        "          \"at the p < 0.05 significance level.\")\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a782b51"
      },
      "source": [
        "## Define Bootstrapping and Training Parameters\n",
        "\n",
        "### Subtask:\n",
        "Set constants for the number of bootstrap iterations and training epochs per iteration. Initialize a list to store latent adjacency matrices from each bootstrap run. Define a helper function to convert latent graph `Data` objects into adjacency matrices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1a74fc5"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to set the constants for bootstrap iterations and epochs, initialize a list for latent adjacency matrices, and define a helper function to convert latent graph Data objects into adjacency matrices, as specified in the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c42dca5"
      },
      "source": [
        "num_bootstrap_iterations = 500\n",
        "bootstrap_epochs = 50\n",
        "all_bootstrap_latent_adj_matrices = []\n",
        "\n",
        "def latent_data_to_adj_matrix(latent_data):\n",
        "    num_nodes = latent_data.num_nodes\n",
        "    # Initialize latent_adj on the same device as latent_data.x\n",
        "    latent_adj = torch.zeros(num_nodes, num_nodes, device=latent_data.x.device)\n",
        "\n",
        "    if hasattr(latent_data, 'edge_attr') and latent_data.edge_attr is not None and latent_data.edge_attr.numel() > 0:\n",
        "        edge_attr_squeeze = latent_data.edge_attr.squeeze()\n",
        "        if edge_attr_squeeze.dim() == 0: # Handle scalar edge_attr (single edge)\n",
        "            if latent_data.edge_index.size(1) == 1: # Ensure there is indeed one edge\n",
        "                latent_adj[latent_data.edge_index[0, 0], latent_data.edge_index[1, 0]] = edge_attr_squeeze\n",
        "        else: # Handle tensor edge_attr (multiple edges)\n",
        "            if edge_attr_squeeze.size(0) == latent_data.edge_index.size(1): # Ensure size matches number of edges\n",
        "                latent_adj[latent_data.edge_index[0], latent_data.edge_index[1]] = edge_attr_squeeze\n",
        "\n",
        "    # Ensure latent_adj is symmetric by averaging it with its transpose\n",
        "    latent_adj = 0.5 * (latent_adj + latent_adj.transpose(0, 1))\n",
        "    return latent_adj.cpu() # Return to CPU for storage and further processing if desired"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4415232"
      },
      "source": [
        "## Bootstrap Loop - Train HVAE and Extract Latent Adjacency Matrices\n",
        "\n",
        "### Subtask:\n",
        "Perform multiple bootstrap iterations. In each iteration, sample data, prepare a new DataLoader, re-initialize and train the HVAE model, extract latent representations for all original graphs using the newly trained encoder, and convert these into latent adjacency matrices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c371798d"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to implement the bootstrap loop as described, which involves iterating, sampling data, training a new HVAE model, extracting latent representations for all original graphs, converting them to adjacency matrices, and storing the results. This will all be done in a single code block to ensure continuity and correct variable scope.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d9eee07"
      },
      "source": [
        "**Reasoning**:\n",
        "The error `TypeError: randint() received an invalid combination of arguments - got (int, int, tuple, replacement=bool)` indicates that `replacement=True` is not a valid argument for `torch.randint`. The `torch.randint(low, high, size)` function already samples integers with replacement implicitly when the `size` argument allows for duplicates, which is the case here as we are sampling `num_original_graphs` indices from a range of `num_original_graphs` values. Therefore, removing the `replacement=True` argument will fix the `TypeError` while maintaining the intended sampling logic.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ecfec7a"
      },
      "source": [
        "## Correct torch.randint Call\n",
        "\n",
        "### Subtask:\n",
        "Modify the `torch.randint` function call to fix the `TypeError` by removing the `replacement=True` argument.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "245f51d4"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed due to an invalid argument `replacement=True` in `torch.randint`. This `TypeError` can be fixed by removing this argument, as `torch.randint` implicitly samples with replacement when the size allows for duplicates. The updated code will include this fix while retaining the rest of the bootstrap loop logic.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7df132df",
        "outputId": "aad02343-a33e-4011-f15e-32c590569278"
      },
      "source": [
        "num_original_graphs = len(graphs)\n",
        "\n",
        "# Bootstrap Loop\n",
        "for bootstrap_idx in range(num_bootstrap_iterations):\n",
        "    print(f\"\\n--- Bootstrap Iteration {bootstrap_idx + 1}/{num_bootstrap_iterations} ---\")\n",
        "\n",
        "    # 1. Sample Data: Randomly sample num_original_graphs indices with replacement\n",
        "    # Removed 'replacement=True' as it's not a valid argument for torch.randint\n",
        "    sampled_indices = torch.randint(0, num_original_graphs, (num_original_graphs,)).tolist()\n",
        "    bootstrapped_graphs = [graphs[i] for i in sampled_indices]\n",
        "\n",
        "    # 2. Prepare Bootstrapped DataLoader\n",
        "    bootstrapped_loader = DataLoader(bootstrapped_graphs, batch_size=32, shuffle=True)\n",
        "\n",
        "    # 3. Initialize and Train HVAE\n",
        "    # Re-initialize model and optimizer for each bootstrap iteration\n",
        "    model_graph_vae_bootstrap = GraphToGraphVAE(in_channels=64, hidden_channels=128, pooled_ratio=0.25, original_num_nodes=64).to(device)\n",
        "    optimizer_graph_vae_bootstrap = optim.Adam(model_graph_vae_bootstrap.parameters(), lr=1e-3)\n",
        "\n",
        "    model_graph_vae_bootstrap.train()\n",
        "    print(f\"Training HVAE for {bootstrap_epochs} epochs on bootstrapped data...\")\n",
        "\n",
        "    for epoch in range(bootstrap_epochs):\n",
        "        total_loss = 0\n",
        "        total_recon = 0\n",
        "        total_kl = 0\n",
        "        num_graphs_processed = 0\n",
        "\n",
        "        for batch in bootstrapped_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer_graph_vae_bootstrap.zero_grad()\n",
        "            recon_adj, mu, logvar = model_graph_vae_bootstrap(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
        "\n",
        "            original_adj = torch.zeros(batch.num_graphs, 64, 64, device=device)\n",
        "            original_data_list = batch.to_data_list()\n",
        "            for j, data in enumerate(original_data_list):\n",
        "                adj_graph = torch.zeros(data.num_nodes, data.num_nodes, device=device)\n",
        "                if data.edge_attr is not None and data.edge_attr.numel() > 0:\n",
        "                    edge_attr_squeeze = data.edge_attr.squeeze()\n",
        "                    if edge_attr_squeeze.dim() == 0 and data.edge_index.size(1) == 1:\n",
        "                        adj_graph[data.edge_index[0, 0], data.edge_index[1, 0]] = edge_attr_squeeze\n",
        "                    elif edge_attr_squeeze.dim() > 0 and edge_attr_squeeze.size(0) == data.edge_index.size(1):\n",
        "                        adj_graph[data.edge_index[0], data.edge_index[1]] = edge_attr_squeeze\n",
        "                adj_graph = 0.5 * (adj_graph + adj_graph.transpose(0, 1)) # Symmetrize\n",
        "                original_adj[j] = adj_graph\n",
        "\n",
        "            loss, recon, kl = loss_function(recon_adj, original_adj, mu, logvar)\n",
        "            loss.backward()\n",
        "            optimizer_graph_vae_bootstrap.step()\n",
        "\n",
        "            total_loss += loss.item() * batch.num_graphs\n",
        "            total_recon += recon.item() * batch.num_graphs\n",
        "            total_kl += kl.item() * batch.num_graphs\n",
        "            num_graphs_processed += batch.num_graphs\n",
        "\n",
        "        avg_loss = total_loss / num_graphs_processed if num_graphs_processed > 0 else 0\n",
        "        avg_recon = total_recon / num_graphs_processed if num_graphs_processed > 0 else 0\n",
        "        avg_kl = total_kl / num_graphs_processed if num_graphs_processed > 0 else 0\n",
        "\n",
        "        if (epoch + 1) % 10 == 0 or epoch == 0 or epoch == bootstrap_epochs - 1:\n",
        "            print(f\"  Epoch {epoch+1:03d} | Avg Total Loss: {avg_loss:.6f} | Avg Recon: {avg_recon:.6f} | Avg KL: {avg_kl:.6f}\")\n",
        "\n",
        "\n",
        "    # 4. Extract Latent Representations for ALL Original Graphs (not just bootstrapped sample)\n",
        "    model_encoder_inference_bootstrap = GraphVAE_Encoder_Inference(\n",
        "        in_channels=64,\n",
        "        hidden_channels=128,\n",
        "        pooled_ratio=0.25\n",
        "    ).to(device)\n",
        "    model_encoder_inference_bootstrap.load_state_dict(model_graph_vae_bootstrap.encoder.state_dict())\n",
        "    model_encoder_inference_bootstrap.eval()\n",
        "\n",
        "    current_bootstrap_latent_graphs_data_list = []\n",
        "    with torch.no_grad():\n",
        "        for graph in graphs: # Process ALL original graphs\n",
        "            single_graph_on_device = graph.to(device)\n",
        "            batch_tensor = torch.zeros(single_graph_on_device.num_nodes, dtype=torch.long, device=device)\n",
        "            latent_graph_data, pooled_indices = model_encoder_inference_bootstrap(\n",
        "                single_graph_on_device.x,\n",
        "                single_graph_on_device.edge_index,\n",
        "                single_graph_on_device.edge_attr,\n",
        "                batch_tensor\n",
        "            )\n",
        "            current_bootstrap_latent_graphs_data_list.append((latent_graph_data.cpu(), pooled_indices.cpu()))\n",
        "\n",
        "    # 5. Convert to Latent Adjacency Matrices (approx 16x16)\n",
        "    current_bootstrap_latent_adj_matrices = [\n",
        "        latent_data_to_adj_matrix(latent_data)\n",
        "        for latent_data, _ in current_bootstrap_latent_graphs_data_list\n",
        "    ]\n",
        "\n",
        "    all_bootstrap_latent_adj_matrices.append(torch.stack(current_bootstrap_latent_adj_matrices))\n",
        "    print(f\"Finished bootstrap iteration {bootstrap_idx + 1}. Extracted latent matrices for all {len(graphs)} original graphs.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Bootstrap Iteration 1/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2893396060.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  bootstrapped_loader = DataLoader(bootstrapped_graphs, batch_size=32, shuffle=True)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 001 | Avg Total Loss: 0.002926 | Avg Recon: 0.001842 | Avg KL: 0.001084\n",
            "  Epoch 010 | Avg Total Loss: 0.000269 | Avg Recon: 0.000267 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000192 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 1. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 2/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002937 | Avg Recon: 0.001903 | Avg KL: 0.001034\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000287 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000201 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 2. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 3/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003219 | Avg Recon: 0.001890 | Avg KL: 0.001330\n",
            "  Epoch 010 | Avg Total Loss: 0.000273 | Avg Recon: 0.000272 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 3. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 4/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003046 | Avg Recon: 0.002003 | Avg KL: 0.001043\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000285 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 4. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 5/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003518 | Avg Recon: 0.001895 | Avg KL: 0.001623\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000275 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 5. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 6/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003138 | Avg Recon: 0.001968 | Avg KL: 0.001171\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000290 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 6. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 7/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003109 | Avg Recon: 0.001938 | Avg KL: 0.001171\n",
            "  Epoch 010 | Avg Total Loss: 0.000272 | Avg Recon: 0.000270 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000187 | Avg Recon: 0.000186 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000160 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000156 | Avg Recon: 0.000156 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 7. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 8/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003032 | Avg Recon: 0.001917 | Avg KL: 0.001115\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000272 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000187 | Avg Recon: 0.000187 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000161 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000156 | Avg Recon: 0.000156 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 8. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 9/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003155 | Avg Recon: 0.001987 | Avg KL: 0.001168\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000162 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 9. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 10/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003082 | Avg Recon: 0.001991 | Avg KL: 0.001091\n",
            "  Epoch 010 | Avg Total Loss: 0.000308 | Avg Recon: 0.000306 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000216 | Avg Recon: 0.000215 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000188 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000184 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 10. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 11/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003166 | Avg Recon: 0.001892 | Avg KL: 0.001274\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 11. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 12/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003085 | Avg Recon: 0.001989 | Avg KL: 0.001096\n",
            "  Epoch 010 | Avg Total Loss: 0.000272 | Avg Recon: 0.000271 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000157 | Avg Recon: 0.000157 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000154 | Avg Recon: 0.000154 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 12. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 13/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002957 | Avg Recon: 0.001892 | Avg KL: 0.001066\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000272 | Avg KL: 0.000003\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 13. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 14/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002980 | Avg Recon: 0.001875 | Avg KL: 0.001105\n",
            "  Epoch 010 | Avg Total Loss: 0.000260 | Avg Recon: 0.000259 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000156 | Avg Recon: 0.000156 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000153 | Avg Recon: 0.000153 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 14. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 15/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003107 | Avg Recon: 0.001926 | Avg KL: 0.001181\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000278 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000193 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 15. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 16/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003177 | Avg Recon: 0.002009 | Avg KL: 0.001168\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000286 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 16. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 17/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003020 | Avg Recon: 0.001971 | Avg KL: 0.001049\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000289 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000204 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 17. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 18/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003047 | Avg Recon: 0.002000 | Avg KL: 0.001047\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 18. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 19/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003113 | Avg Recon: 0.001975 | Avg KL: 0.001138\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 19. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 20/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002863 | Avg Recon: 0.001896 | Avg KL: 0.000968\n",
            "  Epoch 010 | Avg Total Loss: 0.000272 | Avg Recon: 0.000271 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000159 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000156 | Avg Recon: 0.000155 | Avg KL: 0.000001\n",
            "Finished bootstrap iteration 20. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 21/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003245 | Avg Recon: 0.002067 | Avg KL: 0.001178\n",
            "  Epoch 010 | Avg Total Loss: 0.000297 | Avg Recon: 0.000295 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000184 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 21. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 22/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003019 | Avg Recon: 0.001919 | Avg KL: 0.001100\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 22. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 23/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003193 | Avg Recon: 0.001972 | Avg KL: 0.001221\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 23. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 24/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003157 | Avg Recon: 0.001920 | Avg KL: 0.001236\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 24. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 25/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003034 | Avg Recon: 0.001899 | Avg KL: 0.001135\n",
            "  Epoch 010 | Avg Total Loss: 0.000278 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 25. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 26/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003023 | Avg Recon: 0.002050 | Avg KL: 0.000973\n",
            "  Epoch 010 | Avg Total Loss: 0.000290 | Avg Recon: 0.000289 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 26. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 27/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003009 | Avg Recon: 0.001997 | Avg KL: 0.001012\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 27. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 28/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003101 | Avg Recon: 0.001896 | Avg KL: 0.001205\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000287 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000203 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 28. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 29/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002940 | Avg Recon: 0.001913 | Avg KL: 0.001026\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000286 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000208 | Avg Recon: 0.000207 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000188 | Avg Recon: 0.000188 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 29. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 30/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003016 | Avg Recon: 0.001919 | Avg KL: 0.001097\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 30. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 31/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002911 | Avg Recon: 0.001926 | Avg KL: 0.000985\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000276 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 31. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 32/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003205 | Avg Recon: 0.002046 | Avg KL: 0.001159\n",
            "  Epoch 010 | Avg Total Loss: 0.000308 | Avg Recon: 0.000307 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000216 | Avg Recon: 0.000215 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000195 | Avg Recon: 0.000194 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000188 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 32. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 33/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003159 | Avg Recon: 0.001965 | Avg KL: 0.001194\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000286 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 33. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 34/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002802 | Avg Recon: 0.001947 | Avg KL: 0.000855\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000276 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000001\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 34. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 35/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003023 | Avg Recon: 0.001945 | Avg KL: 0.001078\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000284 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000200 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 35. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 36/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003212 | Avg Recon: 0.002081 | Avg KL: 0.001131\n",
            "  Epoch 010 | Avg Total Loss: 0.000295 | Avg Recon: 0.000293 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 36. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 37/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003010 | Avg Recon: 0.001900 | Avg KL: 0.001110\n",
            "  Epoch 010 | Avg Total Loss: 0.000295 | Avg Recon: 0.000291 | Avg KL: 0.000004\n",
            "  Epoch 020 | Avg Total Loss: 0.000207 | Avg Recon: 0.000206 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000189 | Avg Recon: 0.000189 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 37. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 38/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002860 | Avg Recon: 0.001905 | Avg KL: 0.000955\n",
            "  Epoch 010 | Avg Total Loss: 0.000266 | Avg Recon: 0.000265 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000157 | Avg Recon: 0.000157 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 38. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 39/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003134 | Avg Recon: 0.001874 | Avg KL: 0.001260\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000274 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000193 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 39. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 40/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002855 | Avg Recon: 0.001941 | Avg KL: 0.000913\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000288 | Avg KL: 0.000003\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000205 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 40. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 41/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002954 | Avg Recon: 0.002014 | Avg KL: 0.000940\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000192 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 41. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 42/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003106 | Avg Recon: 0.001974 | Avg KL: 0.001132\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000285 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 42. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 43/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003242 | Avg Recon: 0.002021 | Avg KL: 0.001221\n",
            "  Epoch 010 | Avg Total Loss: 0.000303 | Avg Recon: 0.000302 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000211 | Avg Recon: 0.000210 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000184 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 43. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 44/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003095 | Avg Recon: 0.001958 | Avg KL: 0.001137\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 44. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 45/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003171 | Avg Recon: 0.001948 | Avg KL: 0.001223\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000283 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 45. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 46/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002808 | Avg Recon: 0.001929 | Avg KL: 0.000879\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000286 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000184 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 46. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 47/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002995 | Avg Recon: 0.001961 | Avg KL: 0.001034\n",
            "  Epoch 010 | Avg Total Loss: 0.000296 | Avg Recon: 0.000294 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000206 | Avg Recon: 0.000205 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000187 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 47. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 48/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003343 | Avg Recon: 0.002012 | Avg KL: 0.001331\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000274 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000157 | Avg Recon: 0.000156 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000153 | Avg Recon: 0.000153 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 48. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 49/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003214 | Avg Recon: 0.002010 | Avg KL: 0.001204\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000284 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000189 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000158 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 49. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 50/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002959 | Avg Recon: 0.001889 | Avg KL: 0.001070\n",
            "  Epoch 010 | Avg Total Loss: 0.000263 | Avg Recon: 0.000262 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000162 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000156 | Avg Recon: 0.000155 | Avg KL: 0.000001\n",
            "  Epoch 050 | Avg Total Loss: 0.000152 | Avg Recon: 0.000152 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 50. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 51/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003090 | Avg Recon: 0.002010 | Avg KL: 0.001080\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000290 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000204 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000184 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 51. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 52/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003030 | Avg Recon: 0.001992 | Avg KL: 0.001038\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000290 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000207 | Avg Recon: 0.000207 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000187 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 52. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 53/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003006 | Avg Recon: 0.001968 | Avg KL: 0.001038\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000276 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000156 | Avg Recon: 0.000155 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 53. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 54/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002943 | Avg Recon: 0.001932 | Avg KL: 0.001011\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000286 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000184 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 54. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 55/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003083 | Avg Recon: 0.001974 | Avg KL: 0.001109\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000284 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000199 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 55. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 56/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003104 | Avg Recon: 0.001924 | Avg KL: 0.001180\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000290 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 56. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 57/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003163 | Avg Recon: 0.001916 | Avg KL: 0.001248\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000275 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000192 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 57. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 58/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002894 | Avg Recon: 0.001855 | Avg KL: 0.001039\n",
            "  Epoch 010 | Avg Total Loss: 0.000268 | Avg Recon: 0.000266 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000158 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 58. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 59/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003145 | Avg Recon: 0.001917 | Avg KL: 0.001229\n",
            "  Epoch 010 | Avg Total Loss: 0.000294 | Avg Recon: 0.000292 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000188 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 59. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 60/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003227 | Avg Recon: 0.002018 | Avg KL: 0.001210\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000286 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 60. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 61/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003081 | Avg Recon: 0.001989 | Avg KL: 0.001093\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000278 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000163 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 61. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 62/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002830 | Avg Recon: 0.001892 | Avg KL: 0.000938\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 62. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 63/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003056 | Avg Recon: 0.001924 | Avg KL: 0.001131\n",
            "  Epoch 010 | Avg Total Loss: 0.000268 | Avg Recon: 0.000267 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000163 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000156 | Avg Recon: 0.000156 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000153 | Avg Recon: 0.000153 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 63. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 64/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003001 | Avg Recon: 0.001907 | Avg KL: 0.001094\n",
            "  Epoch 010 | Avg Total Loss: 0.000290 | Avg Recon: 0.000288 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 64. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 65/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003004 | Avg Recon: 0.001934 | Avg KL: 0.001071\n",
            "  Epoch 010 | Avg Total Loss: 0.000294 | Avg Recon: 0.000293 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000209 | Avg Recon: 0.000208 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000190 | Avg Recon: 0.000190 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 65. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 66/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002920 | Avg Recon: 0.001953 | Avg KL: 0.000967\n",
            "  Epoch 010 | Avg Total Loss: 0.000290 | Avg Recon: 0.000288 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000181 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 66. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 67/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002816 | Avg Recon: 0.001905 | Avg KL: 0.000911\n",
            "  Epoch 010 | Avg Total Loss: 0.000273 | Avg Recon: 0.000272 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 67. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 68/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003162 | Avg Recon: 0.002024 | Avg KL: 0.001138\n",
            "  Epoch 010 | Avg Total Loss: 0.000295 | Avg Recon: 0.000294 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000207 | Avg Recon: 0.000207 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000187 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 68. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 69/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003128 | Avg Recon: 0.001955 | Avg KL: 0.001174\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 69. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 70/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003256 | Avg Recon: 0.001953 | Avg KL: 0.001303\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 70. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 71/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003048 | Avg Recon: 0.001983 | Avg KL: 0.001065\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000291 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 71. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 72/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003219 | Avg Recon: 0.001970 | Avg KL: 0.001249\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000282 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 72. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 73/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002950 | Avg Recon: 0.001975 | Avg KL: 0.000975\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000276 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 73. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 74/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003011 | Avg Recon: 0.002057 | Avg KL: 0.000953\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000290 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 74. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 75/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003174 | Avg Recon: 0.001919 | Avg KL: 0.001254\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000290 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000205 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000186 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 75. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 76/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003181 | Avg Recon: 0.001963 | Avg KL: 0.001218\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000286 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 76. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 77/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003125 | Avg Recon: 0.001905 | Avg KL: 0.001220\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 77. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 78/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003034 | Avg Recon: 0.001889 | Avg KL: 0.001145\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000277 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 78. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 79/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003141 | Avg Recon: 0.001848 | Avg KL: 0.001293\n",
            "  Epoch 010 | Avg Total Loss: 0.000266 | Avg Recon: 0.000264 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000158 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000155 | Avg Recon: 0.000155 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 79. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 80/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003084 | Avg Recon: 0.001918 | Avg KL: 0.001166\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000276 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000195 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 80. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 81/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002890 | Avg Recon: 0.001884 | Avg KL: 0.001006\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 81. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 82/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003037 | Avg Recon: 0.001980 | Avg KL: 0.001057\n",
            "  Epoch 010 | Avg Total Loss: 0.000278 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000163 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 82. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 83/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002982 | Avg Recon: 0.001953 | Avg KL: 0.001030\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 83. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 84/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002916 | Avg Recon: 0.001865 | Avg KL: 0.001050\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000274 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 84. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 85/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002888 | Avg Recon: 0.001959 | Avg KL: 0.000928\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000289 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 85. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 86/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003126 | Avg Recon: 0.001970 | Avg KL: 0.001157\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000193 | Avg KL: 0.000002\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 86. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 87/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003071 | Avg Recon: 0.001980 | Avg KL: 0.001091\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000161 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000158 | Avg Recon: 0.000157 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 87. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 88/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002871 | Avg Recon: 0.001913 | Avg KL: 0.000958\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 88. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 89/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002873 | Avg Recon: 0.001931 | Avg KL: 0.000942\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000286 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000208 | Avg Recon: 0.000207 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000189 | Avg Recon: 0.000189 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 89. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 90/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003047 | Avg Recon: 0.001943 | Avg KL: 0.001104\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000284 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 90. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 91/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003189 | Avg Recon: 0.002083 | Avg KL: 0.001106\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000286 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 91. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 92/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002950 | Avg Recon: 0.001912 | Avg KL: 0.001037\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 92. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 93/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003074 | Avg Recon: 0.001914 | Avg KL: 0.001160\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000283 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 93. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 94/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003120 | Avg Recon: 0.002015 | Avg KL: 0.001105\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000283 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 94. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 95/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002997 | Avg Recon: 0.001956 | Avg KL: 0.001041\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000278 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 95. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 96/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003013 | Avg Recon: 0.001880 | Avg KL: 0.001132\n",
            "  Epoch 010 | Avg Total Loss: 0.000271 | Avg Recon: 0.000270 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000188 | Avg Recon: 0.000187 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 96. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 97/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002993 | Avg Recon: 0.001992 | Avg KL: 0.001001\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000290 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000181 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 97. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 98/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002978 | Avg Recon: 0.001965 | Avg KL: 0.001013\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000288 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000200 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 98. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 99/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003027 | Avg Recon: 0.001960 | Avg KL: 0.001067\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000286 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 99. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 100/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003338 | Avg Recon: 0.001845 | Avg KL: 0.001493\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 100. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 101/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003150 | Avg Recon: 0.002041 | Avg KL: 0.001109\n",
            "  Epoch 010 | Avg Total Loss: 0.000295 | Avg Recon: 0.000293 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 101. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 102/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003049 | Avg Recon: 0.001984 | Avg KL: 0.001065\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000284 | Avg KL: 0.000003\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 102. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 103/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003017 | Avg Recon: 0.001988 | Avg KL: 0.001029\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000279 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000197 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 103. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 104/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003048 | Avg Recon: 0.002020 | Avg KL: 0.001028\n",
            "  Epoch 010 | Avg Total Loss: 0.000295 | Avg Recon: 0.000293 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 104. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 105/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003284 | Avg Recon: 0.002052 | Avg KL: 0.001232\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000288 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 105. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 106/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002882 | Avg Recon: 0.001847 | Avg KL: 0.001035\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000272 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 106. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 107/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003065 | Avg Recon: 0.001911 | Avg KL: 0.001154\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000278 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 107. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 108/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003007 | Avg Recon: 0.001947 | Avg KL: 0.001060\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000285 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 108. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 109/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002879 | Avg Recon: 0.001850 | Avg KL: 0.001029\n",
            "  Epoch 010 | Avg Total Loss: 0.000271 | Avg Recon: 0.000270 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 109. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 110/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002846 | Avg Recon: 0.001911 | Avg KL: 0.000935\n",
            "  Epoch 010 | Avg Total Loss: 0.000268 | Avg Recon: 0.000265 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000166 | Avg Recon: 0.000165 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000158 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000155 | Avg Recon: 0.000155 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 110. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 111/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003036 | Avg Recon: 0.001932 | Avg KL: 0.001104\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 111. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 112/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002765 | Avg Recon: 0.001873 | Avg KL: 0.000892\n",
            "  Epoch 010 | Avg Total Loss: 0.000278 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 112. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 113/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002983 | Avg Recon: 0.002051 | Avg KL: 0.000932\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000289 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 113. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 114/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003048 | Avg Recon: 0.001954 | Avg KL: 0.001094\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000280 | Avg KL: 0.000003\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000192 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 114. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 115/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003086 | Avg Recon: 0.001901 | Avg KL: 0.001185\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 115. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 116/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003140 | Avg Recon: 0.001931 | Avg KL: 0.001209\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000283 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 116. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 117/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003312 | Avg Recon: 0.002119 | Avg KL: 0.001193\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000284 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000192 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000158 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 117. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 118/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002876 | Avg Recon: 0.001981 | Avg KL: 0.000895\n",
            "  Epoch 010 | Avg Total Loss: 0.000269 | Avg Recon: 0.000267 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000155 | Avg Recon: 0.000155 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 118. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 119/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002978 | Avg Recon: 0.001919 | Avg KL: 0.001059\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000279 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 119. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 120/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003105 | Avg Recon: 0.002002 | Avg KL: 0.001102\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000286 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000199 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 120. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 121/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003110 | Avg Recon: 0.001963 | Avg KL: 0.001148\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 121. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 122/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002993 | Avg Recon: 0.001902 | Avg KL: 0.001091\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 122. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 123/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003195 | Avg Recon: 0.002028 | Avg KL: 0.001167\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000285 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 123. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 124/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003099 | Avg Recon: 0.001900 | Avg KL: 0.001199\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 124. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 125/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003078 | Avg Recon: 0.002004 | Avg KL: 0.001074\n",
            "  Epoch 010 | Avg Total Loss: 0.000297 | Avg Recon: 0.000296 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000207 | Avg Recon: 0.000207 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000187 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 125. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 126/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002989 | Avg Recon: 0.001958 | Avg KL: 0.001031\n",
            "  Epoch 010 | Avg Total Loss: 0.000295 | Avg Recon: 0.000294 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000213 | Avg Recon: 0.000213 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000194 | Avg Recon: 0.000193 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000187 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000184 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 126. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 127/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003069 | Avg Recon: 0.001895 | Avg KL: 0.001174\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000278 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000192 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 127. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 128/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002996 | Avg Recon: 0.001908 | Avg KL: 0.001089\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 128. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 129/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003027 | Avg Recon: 0.001932 | Avg KL: 0.001095\n",
            "  Epoch 010 | Avg Total Loss: 0.000296 | Avg Recon: 0.000295 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000210 | Avg Recon: 0.000209 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000189 | Avg Recon: 0.000189 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 129. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 130/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003373 | Avg Recon: 0.001936 | Avg KL: 0.001437\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000283 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 130. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 131/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003074 | Avg Recon: 0.001966 | Avg KL: 0.001109\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000290 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000184 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 131. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 132/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003078 | Avg Recon: 0.001947 | Avg KL: 0.001131\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000285 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 132. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 133/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003130 | Avg Recon: 0.001911 | Avg KL: 0.001218\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 133. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 134/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002974 | Avg Recon: 0.001913 | Avg KL: 0.001061\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000276 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000193 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 134. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 135/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003239 | Avg Recon: 0.002022 | Avg KL: 0.001216\n",
            "  Epoch 010 | Avg Total Loss: 0.000304 | Avg Recon: 0.000302 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000212 | Avg Recon: 0.000212 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000190 | Avg Recon: 0.000190 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 135. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 136/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003023 | Avg Recon: 0.001900 | Avg KL: 0.001122\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 136. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 137/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003184 | Avg Recon: 0.002023 | Avg KL: 0.001161\n",
            "  Epoch 010 | Avg Total Loss: 0.000299 | Avg Recon: 0.000297 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000210 | Avg Recon: 0.000209 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000188 | Avg Recon: 0.000188 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 137. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 138/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003078 | Avg Recon: 0.001950 | Avg KL: 0.001129\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 138. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 139/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003010 | Avg Recon: 0.001908 | Avg KL: 0.001102\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000274 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 139. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 140/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002974 | Avg Recon: 0.001939 | Avg KL: 0.001035\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 140. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 141/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002862 | Avg Recon: 0.001903 | Avg KL: 0.000959\n",
            "  Epoch 010 | Avg Total Loss: 0.000273 | Avg Recon: 0.000272 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 141. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 142/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003069 | Avg Recon: 0.002002 | Avg KL: 0.001067\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000287 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 142. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 143/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002961 | Avg Recon: 0.001916 | Avg KL: 0.001045\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000001\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 143. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 144/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002971 | Avg Recon: 0.001888 | Avg KL: 0.001082\n",
            "  Epoch 010 | Avg Total Loss: 0.000270 | Avg Recon: 0.000269 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000189 | Avg Recon: 0.000188 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000162 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 144. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 145/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003162 | Avg Recon: 0.001957 | Avg KL: 0.001205\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000283 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 145. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 146/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003056 | Avg Recon: 0.001934 | Avg KL: 0.001122\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000283 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 146. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 147/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002944 | Avg Recon: 0.001917 | Avg KL: 0.001027\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000197 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 147. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 148/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002870 | Avg Recon: 0.001848 | Avg KL: 0.001023\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000274 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 148. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 149/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002959 | Avg Recon: 0.001911 | Avg KL: 0.001048\n",
            "  Epoch 010 | Avg Total Loss: 0.000269 | Avg Recon: 0.000268 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000160 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000156 | Avg Recon: 0.000156 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 149. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 150/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003019 | Avg Recon: 0.001922 | Avg KL: 0.001097\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 150. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 151/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002904 | Avg Recon: 0.001933 | Avg KL: 0.000971\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 151. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 152/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003204 | Avg Recon: 0.001958 | Avg KL: 0.001246\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 152. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 153/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002998 | Avg Recon: 0.001953 | Avg KL: 0.001045\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000192 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 153. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 154/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003088 | Avg Recon: 0.001881 | Avg KL: 0.001207\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 154. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 155/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003051 | Avg Recon: 0.001920 | Avg KL: 0.001131\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000289 | Avg KL: 0.000003\n",
            "  Epoch 020 | Avg Total Loss: 0.000207 | Avg Recon: 0.000207 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000188 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 155. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 156/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002957 | Avg Recon: 0.001910 | Avg KL: 0.001047\n",
            "  Epoch 010 | Avg Total Loss: 0.000278 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 156. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 157/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002899 | Avg Recon: 0.001886 | Avg KL: 0.001013\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000186 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 157. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 158/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003299 | Avg Recon: 0.001911 | Avg KL: 0.001388\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000169 | Avg KL: 0.000001\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 158. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 159/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003238 | Avg Recon: 0.001944 | Avg KL: 0.001294\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000291 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 159. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 160/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003072 | Avg Recon: 0.001842 | Avg KL: 0.001230\n",
            "  Epoch 010 | Avg Total Loss: 0.000260 | Avg Recon: 0.000258 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000181 | Avg Recon: 0.000180 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000163 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000156 | Avg Recon: 0.000155 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000153 | Avg Recon: 0.000153 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 160. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 161/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002999 | Avg Recon: 0.001879 | Avg KL: 0.001120\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 161. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 162/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003068 | Avg Recon: 0.001941 | Avg KL: 0.001126\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000286 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 162. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 163/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003235 | Avg Recon: 0.001948 | Avg KL: 0.001286\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000287 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 163. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 164/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003122 | Avg Recon: 0.001888 | Avg KL: 0.001234\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 164. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 165/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003192 | Avg Recon: 0.001923 | Avg KL: 0.001269\n",
            "  Epoch 010 | Avg Total Loss: 0.000290 | Avg Recon: 0.000288 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 165. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 166/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002951 | Avg Recon: 0.001881 | Avg KL: 0.001069\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000276 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 166. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 167/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003026 | Avg Recon: 0.001857 | Avg KL: 0.001169\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000287 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 167. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 168/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003087 | Avg Recon: 0.001894 | Avg KL: 0.001193\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000281 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 168. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 169/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003125 | Avg Recon: 0.001913 | Avg KL: 0.001212\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 169. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 170/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003075 | Avg Recon: 0.001855 | Avg KL: 0.001220\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000184 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 170. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 171/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003236 | Avg Recon: 0.001944 | Avg KL: 0.001292\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000288 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000205 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 171. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 172/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002877 | Avg Recon: 0.001872 | Avg KL: 0.001005\n",
            "  Epoch 010 | Avg Total Loss: 0.000269 | Avg Recon: 0.000267 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 172. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 173/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003032 | Avg Recon: 0.001887 | Avg KL: 0.001145\n",
            "  Epoch 010 | Avg Total Loss: 0.000268 | Avg Recon: 0.000265 | Avg KL: 0.000003\n",
            "  Epoch 020 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000154 | Avg Recon: 0.000154 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000152 | Avg Recon: 0.000152 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 173. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 174/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002999 | Avg Recon: 0.001948 | Avg KL: 0.001051\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000279 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 174. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 175/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002963 | Avg Recon: 0.001988 | Avg KL: 0.000975\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000284 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 175. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 176/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002889 | Avg Recon: 0.001927 | Avg KL: 0.000961\n",
            "  Epoch 010 | Avg Total Loss: 0.000271 | Avg Recon: 0.000269 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000165 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000157 | Avg Recon: 0.000157 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000155 | Avg Recon: 0.000154 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 176. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 177/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002853 | Avg Recon: 0.001857 | Avg KL: 0.000996\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 177. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 178/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002907 | Avg Recon: 0.001823 | Avg KL: 0.001084\n",
            "  Epoch 010 | Avg Total Loss: 0.000273 | Avg Recon: 0.000272 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 178. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 179/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002964 | Avg Recon: 0.001888 | Avg KL: 0.001076\n",
            "  Epoch 010 | Avg Total Loss: 0.000278 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 179. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 180/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003041 | Avg Recon: 0.001932 | Avg KL: 0.001109\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 180. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 181/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003224 | Avg Recon: 0.002031 | Avg KL: 0.001192\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000290 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000199 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 181. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 182/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002987 | Avg Recon: 0.001961 | Avg KL: 0.001027\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 182. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 183/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003080 | Avg Recon: 0.001998 | Avg KL: 0.001081\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000278 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 183. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 184/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003236 | Avg Recon: 0.001905 | Avg KL: 0.001331\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000189 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 184. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 185/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002813 | Avg Recon: 0.001918 | Avg KL: 0.000895\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000291 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 185. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 186/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003203 | Avg Recon: 0.001986 | Avg KL: 0.001217\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000281 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 186. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 187/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003288 | Avg Recon: 0.001930 | Avg KL: 0.001358\n",
            "  Epoch 010 | Avg Total Loss: 0.000278 | Avg Recon: 0.000276 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000187 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000157 | Avg Recon: 0.000157 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 187. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 188/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003035 | Avg Recon: 0.001884 | Avg KL: 0.001152\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000285 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 188. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 189/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002723 | Avg Recon: 0.001805 | Avg KL: 0.000918\n",
            "  Epoch 010 | Avg Total Loss: 0.000262 | Avg Recon: 0.000261 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000166 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000159 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000156 | Avg Recon: 0.000156 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 189. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 190/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003010 | Avg Recon: 0.001967 | Avg KL: 0.001043\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000276 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 190. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 191/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002972 | Avg Recon: 0.001923 | Avg KL: 0.001049\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000286 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 191. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 192/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002987 | Avg Recon: 0.001822 | Avg KL: 0.001164\n",
            "  Epoch 010 | Avg Total Loss: 0.000268 | Avg Recon: 0.000264 | Avg KL: 0.000004\n",
            "  Epoch 020 | Avg Total Loss: 0.000187 | Avg Recon: 0.000186 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 192. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 193/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003150 | Avg Recon: 0.001990 | Avg KL: 0.001159\n",
            "  Epoch 010 | Avg Total Loss: 0.000290 | Avg Recon: 0.000289 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 193. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 194/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003177 | Avg Recon: 0.002063 | Avg KL: 0.001114\n",
            "  Epoch 010 | Avg Total Loss: 0.000295 | Avg Recon: 0.000293 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 194. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 195/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002813 | Avg Recon: 0.001929 | Avg KL: 0.000884\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 195. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 196/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003172 | Avg Recon: 0.002054 | Avg KL: 0.001117\n",
            "  Epoch 010 | Avg Total Loss: 0.000301 | Avg Recon: 0.000299 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000210 | Avg Recon: 0.000209 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000187 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000181 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 196. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 197/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003081 | Avg Recon: 0.001960 | Avg KL: 0.001122\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000290 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000205 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 197. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 198/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003042 | Avg Recon: 0.001954 | Avg KL: 0.001088\n",
            "  Epoch 010 | Avg Total Loss: 0.000294 | Avg Recon: 0.000292 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 198. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 199/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003034 | Avg Recon: 0.001940 | Avg KL: 0.001094\n",
            "  Epoch 010 | Avg Total Loss: 0.000278 | Avg Recon: 0.000276 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000189 | Avg Recon: 0.000188 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 199. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 200/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002850 | Avg Recon: 0.001920 | Avg KL: 0.000930\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 200. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 201/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003117 | Avg Recon: 0.001934 | Avg KL: 0.001183\n",
            "  Epoch 010 | Avg Total Loss: 0.000270 | Avg Recon: 0.000269 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000187 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000157 | Avg Recon: 0.000156 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 201. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 202/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003211 | Avg Recon: 0.001941 | Avg KL: 0.001270\n",
            "  Epoch 010 | Avg Total Loss: 0.000294 | Avg Recon: 0.000293 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000210 | Avg Recon: 0.000210 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000184 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 202. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 203/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002985 | Avg Recon: 0.001932 | Avg KL: 0.001052\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000276 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 203. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 204/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003296 | Avg Recon: 0.001960 | Avg KL: 0.001336\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000285 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 204. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 205/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003334 | Avg Recon: 0.001786 | Avg KL: 0.001548\n",
            "  Epoch 010 | Avg Total Loss: 0.000252 | Avg Recon: 0.000250 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000156 | Avg Recon: 0.000155 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000150 | Avg Recon: 0.000150 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000147 | Avg Recon: 0.000147 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 205. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 206/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003251 | Avg Recon: 0.001979 | Avg KL: 0.001272\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 206. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 207/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003085 | Avg Recon: 0.001940 | Avg KL: 0.001144\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000286 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 207. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 208/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002875 | Avg Recon: 0.001957 | Avg KL: 0.000918\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000284 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 208. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 209/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003149 | Avg Recon: 0.001938 | Avg KL: 0.001212\n",
            "  Epoch 010 | Avg Total Loss: 0.000278 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 209. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 210/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002910 | Avg Recon: 0.001953 | Avg KL: 0.000956\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 210. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 211/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003230 | Avg Recon: 0.001915 | Avg KL: 0.001315\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000285 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 211. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 212/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003151 | Avg Recon: 0.001991 | Avg KL: 0.001160\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 212. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 213/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003085 | Avg Recon: 0.001936 | Avg KL: 0.001149\n",
            "  Epoch 010 | Avg Total Loss: 0.000290 | Avg Recon: 0.000289 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 213. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 214/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002881 | Avg Recon: 0.001905 | Avg KL: 0.000976\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 214. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 215/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002883 | Avg Recon: 0.001860 | Avg KL: 0.001023\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 215. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 216/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003064 | Avg Recon: 0.001862 | Avg KL: 0.001203\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 216. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 217/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003070 | Avg Recon: 0.001911 | Avg KL: 0.001159\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000274 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000190 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 217. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 218/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003161 | Avg Recon: 0.001990 | Avg KL: 0.001171\n",
            "  Epoch 010 | Avg Total Loss: 0.000298 | Avg Recon: 0.000297 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000209 | Avg Recon: 0.000208 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000188 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 218. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 219/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2893396060.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  bootstrapped_loader = DataLoader(bootstrapped_graphs, batch_size=32, shuffle=True)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 001 | Avg Total Loss: 0.003009 | Avg Recon: 0.001865 | Avg KL: 0.001144\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000283 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 219. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 220/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003017 | Avg Recon: 0.001970 | Avg KL: 0.001047\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 220. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 221/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003018 | Avg Recon: 0.001900 | Avg KL: 0.001117\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000278 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 221. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 222/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003010 | Avg Recon: 0.001825 | Avg KL: 0.001186\n",
            "  Epoch 010 | Avg Total Loss: 0.000266 | Avg Recon: 0.000265 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000189 | Avg Recon: 0.000188 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 222. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 223/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003297 | Avg Recon: 0.002011 | Avg KL: 0.001286\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000285 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 223. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 224/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002938 | Avg Recon: 0.001882 | Avg KL: 0.001056\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000287 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000187 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 224. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 225/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003126 | Avg Recon: 0.002000 | Avg KL: 0.001126\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000278 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000189 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000157 | Avg Recon: 0.000157 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 225. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 226/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002949 | Avg Recon: 0.001938 | Avg KL: 0.001011\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 226. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 227/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003171 | Avg Recon: 0.002033 | Avg KL: 0.001138\n",
            "  Epoch 010 | Avg Total Loss: 0.000297 | Avg Recon: 0.000296 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000208 | Avg Recon: 0.000208 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000188 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 227. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 228/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003279 | Avg Recon: 0.002016 | Avg KL: 0.001263\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000192 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 228. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 229/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003059 | Avg Recon: 0.001957 | Avg KL: 0.001102\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000284 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 229. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 230/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003327 | Avg Recon: 0.002032 | Avg KL: 0.001295\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000290 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 230. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 231/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002981 | Avg Recon: 0.001956 | Avg KL: 0.001025\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000284 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000198 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 231. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 232/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2893396060.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  bootstrapped_loader = DataLoader(bootstrapped_graphs, batch_size=32, shuffle=True)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Epoch 001 | Avg Total Loss: 0.002885 | Avg Recon: 0.002031 | Avg KL: 0.000855\n",
            "  Epoch 010 | Avg Total Loss: 0.000290 | Avg Recon: 0.000289 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 232. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 233/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003055 | Avg Recon: 0.001905 | Avg KL: 0.001150\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000279 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 233. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 234/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003331 | Avg Recon: 0.001957 | Avg KL: 0.001374\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000291 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000206 | Avg Recon: 0.000205 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000188 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 234. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 235/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002919 | Avg Recon: 0.001864 | Avg KL: 0.001056\n",
            "  Epoch 010 | Avg Total Loss: 0.000269 | Avg Recon: 0.000268 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 235. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 236/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002967 | Avg Recon: 0.001894 | Avg KL: 0.001073\n",
            "  Epoch 010 | Avg Total Loss: 0.000265 | Avg Recon: 0.000263 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000161 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000153 | Avg Recon: 0.000152 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000150 | Avg Recon: 0.000150 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 236. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 237/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002902 | Avg Recon: 0.001798 | Avg KL: 0.001104\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 237. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 238/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2893396060.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  bootstrapped_loader = DataLoader(bootstrapped_graphs, batch_size=32, shuffle=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 001 | Avg Total Loss: 0.003205 | Avg Recon: 0.001990 | Avg KL: 0.001215\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000289 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 238. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 239/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002744 | Avg Recon: 0.001880 | Avg KL: 0.000865\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 239. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 240/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003440 | Avg Recon: 0.002022 | Avg KL: 0.001418\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000283 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 240. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 241/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003267 | Avg Recon: 0.001917 | Avg KL: 0.001350\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000278 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 241. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 242/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003339 | Avg Recon: 0.002002 | Avg KL: 0.001336\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 242. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 243/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003007 | Avg Recon: 0.001849 | Avg KL: 0.001157\n",
            "  Epoch 010 | Avg Total Loss: 0.000269 | Avg Recon: 0.000267 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000158 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 243. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 244/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003068 | Avg Recon: 0.001982 | Avg KL: 0.001085\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000278 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000001\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 244. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 245/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002924 | Avg Recon: 0.001988 | Avg KL: 0.000937\n",
            "  Epoch 010 | Avg Total Loss: 0.000290 | Avg Recon: 0.000289 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000207 | Avg Recon: 0.000206 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 245. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 246/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003083 | Avg Recon: 0.001995 | Avg KL: 0.001088\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000282 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 246. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 247/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003050 | Avg Recon: 0.001991 | Avg KL: 0.001059\n",
            "  Epoch 010 | Avg Total Loss: 0.000301 | Avg Recon: 0.000300 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000217 | Avg Recon: 0.000217 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000197 | Avg Recon: 0.000197 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000190 | Avg Recon: 0.000189 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000187 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 247. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 248/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002845 | Avg Recon: 0.001827 | Avg KL: 0.001019\n",
            "  Epoch 010 | Avg Total Loss: 0.000270 | Avg Recon: 0.000268 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 248. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 249/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002832 | Avg Recon: 0.001837 | Avg KL: 0.000995\n",
            "  Epoch 010 | Avg Total Loss: 0.000270 | Avg Recon: 0.000269 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 249. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 250/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003018 | Avg Recon: 0.001974 | Avg KL: 0.001043\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000283 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 250. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 251/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002812 | Avg Recon: 0.001840 | Avg KL: 0.000972\n",
            "  Epoch 010 | Avg Total Loss: 0.000269 | Avg Recon: 0.000268 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000158 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 251. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 252/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003184 | Avg Recon: 0.001954 | Avg KL: 0.001231\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 252. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 253/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003287 | Avg Recon: 0.001888 | Avg KL: 0.001400\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000278 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 253. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 254/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003296 | Avg Recon: 0.001843 | Avg KL: 0.001453\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000286 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 254. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 255/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003156 | Avg Recon: 0.001980 | Avg KL: 0.001176\n",
            "  Epoch 010 | Avg Total Loss: 0.000302 | Avg Recon: 0.000300 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000212 | Avg Recon: 0.000212 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000191 | Avg Recon: 0.000191 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000184 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 255. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 256/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002969 | Avg Recon: 0.001909 | Avg KL: 0.001060\n",
            "  Epoch 010 | Avg Total Loss: 0.000264 | Avg Recon: 0.000262 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000154 | Avg Recon: 0.000154 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000151 | Avg Recon: 0.000151 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 256. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 257/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003097 | Avg Recon: 0.001910 | Avg KL: 0.001187\n",
            "  Epoch 010 | Avg Total Loss: 0.000269 | Avg Recon: 0.000268 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000186 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000157 | Avg Recon: 0.000157 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 257. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 258/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003043 | Avg Recon: 0.002002 | Avg KL: 0.001041\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000288 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 258. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 259/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003190 | Avg Recon: 0.001988 | Avg KL: 0.001202\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000284 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000192 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 259. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 260/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003155 | Avg Recon: 0.001971 | Avg KL: 0.001184\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 260. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 261/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003077 | Avg Recon: 0.001999 | Avg KL: 0.001078\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 261. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 262/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002751 | Avg Recon: 0.001897 | Avg KL: 0.000854\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 262. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 263/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003026 | Avg Recon: 0.001959 | Avg KL: 0.001068\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000278 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 263. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 264/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003013 | Avg Recon: 0.001975 | Avg KL: 0.001037\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 264. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 265/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002943 | Avg Recon: 0.001883 | Avg KL: 0.001060\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 265. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 266/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002850 | Avg Recon: 0.001817 | Avg KL: 0.001033\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000274 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 266. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 267/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002747 | Avg Recon: 0.001872 | Avg KL: 0.000875\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000192 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 267. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 268/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003185 | Avg Recon: 0.002028 | Avg KL: 0.001158\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000291 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 268. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 269/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002838 | Avg Recon: 0.001877 | Avg KL: 0.000960\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000274 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000192 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 269. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 270/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003052 | Avg Recon: 0.001956 | Avg KL: 0.001096\n",
            "  Epoch 010 | Avg Total Loss: 0.000290 | Avg Recon: 0.000289 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 270. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 271/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003093 | Avg Recon: 0.001969 | Avg KL: 0.001124\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000289 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 271. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 272/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002829 | Avg Recon: 0.001842 | Avg KL: 0.000987\n",
            "  Epoch 010 | Avg Total Loss: 0.000268 | Avg Recon: 0.000266 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 272. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 273/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003163 | Avg Recon: 0.001915 | Avg KL: 0.001248\n",
            "  Epoch 010 | Avg Total Loss: 0.000273 | Avg Recon: 0.000272 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 273. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 274/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003272 | Avg Recon: 0.001893 | Avg KL: 0.001379\n",
            "  Epoch 010 | Avg Total Loss: 0.000272 | Avg Recon: 0.000271 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000190 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 274. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 275/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003305 | Avg Recon: 0.002005 | Avg KL: 0.001300\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 275. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 276/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002978 | Avg Recon: 0.002029 | Avg KL: 0.000949\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000283 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 276. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 277/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003102 | Avg Recon: 0.001922 | Avg KL: 0.001180\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000288 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 277. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 278/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003077 | Avg Recon: 0.002001 | Avg KL: 0.001076\n",
            "  Epoch 010 | Avg Total Loss: 0.000294 | Avg Recon: 0.000292 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 278. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 279/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002854 | Avg Recon: 0.001890 | Avg KL: 0.000965\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000286 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 279. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 280/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003120 | Avg Recon: 0.001935 | Avg KL: 0.001185\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000285 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000199 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 280. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 281/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003033 | Avg Recon: 0.001915 | Avg KL: 0.001118\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000196 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 281. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 282/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003276 | Avg Recon: 0.001930 | Avg KL: 0.001345\n",
            "  Epoch 010 | Avg Total Loss: 0.000269 | Avg Recon: 0.000267 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000166 | Avg Recon: 0.000165 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000156 | Avg Recon: 0.000156 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 282. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 283/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003015 | Avg Recon: 0.001929 | Avg KL: 0.001086\n",
            "  Epoch 010 | Avg Total Loss: 0.000271 | Avg Recon: 0.000270 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000158 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000155 | Avg Recon: 0.000155 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 283. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 284/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003168 | Avg Recon: 0.002077 | Avg KL: 0.001091\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000287 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 284. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 285/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003245 | Avg Recon: 0.001959 | Avg KL: 0.001286\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000156 | Avg Recon: 0.000155 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 285. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 286/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003278 | Avg Recon: 0.002020 | Avg KL: 0.001258\n",
            "  Epoch 010 | Avg Total Loss: 0.000293 | Avg Recon: 0.000292 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000206 | Avg Recon: 0.000205 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 286. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 287/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003100 | Avg Recon: 0.001946 | Avg KL: 0.001154\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000278 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000189 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 287. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 288/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002989 | Avg Recon: 0.001907 | Avg KL: 0.001082\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000275 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 288. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 289/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002939 | Avg Recon: 0.001960 | Avg KL: 0.000979\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000272 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 289. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 290/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003177 | Avg Recon: 0.002047 | Avg KL: 0.001130\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000286 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 290. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 291/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003103 | Avg Recon: 0.001973 | Avg KL: 0.001130\n",
            "  Epoch 010 | Avg Total Loss: 0.000299 | Avg Recon: 0.000298 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000216 | Avg Recon: 0.000216 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000189 | Avg Recon: 0.000188 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 291. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 292/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003021 | Avg Recon: 0.001856 | Avg KL: 0.001165\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000278 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 292. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 293/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002965 | Avg Recon: 0.001947 | Avg KL: 0.001018\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000196 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 293. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 294/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003047 | Avg Recon: 0.001901 | Avg KL: 0.001145\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000283 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 294. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 295/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003025 | Avg Recon: 0.001841 | Avg KL: 0.001183\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000274 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 295. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 296/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003046 | Avg Recon: 0.001997 | Avg KL: 0.001049\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000288 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 296. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 297/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003004 | Avg Recon: 0.001902 | Avg KL: 0.001102\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 297. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 298/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002793 | Avg Recon: 0.001879 | Avg KL: 0.000915\n",
            "  Epoch 010 | Avg Total Loss: 0.000265 | Avg Recon: 0.000264 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000157 | Avg Recon: 0.000156 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000154 | Avg Recon: 0.000153 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 298. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 299/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003022 | Avg Recon: 0.001995 | Avg KL: 0.001027\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000285 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 299. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 300/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003054 | Avg Recon: 0.001879 | Avg KL: 0.001175\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 300. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 301/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003236 | Avg Recon: 0.002044 | Avg KL: 0.001191\n",
            "  Epoch 010 | Avg Total Loss: 0.000298 | Avg Recon: 0.000295 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000209 | Avg Recon: 0.000208 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000187 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 301. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 302/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003029 | Avg Recon: 0.001820 | Avg KL: 0.001209\n",
            "  Epoch 010 | Avg Total Loss: 0.000268 | Avg Recon: 0.000267 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 302. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 303/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003021 | Avg Recon: 0.001911 | Avg KL: 0.001110\n",
            "  Epoch 010 | Avg Total Loss: 0.000278 | Avg Recon: 0.000277 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 303. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 304/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002926 | Avg Recon: 0.001874 | Avg KL: 0.001052\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000287 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 304. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 305/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002950 | Avg Recon: 0.001973 | Avg KL: 0.000977\n",
            "  Epoch 010 | Avg Total Loss: 0.000290 | Avg Recon: 0.000289 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 305. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 306/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002911 | Avg Recon: 0.001881 | Avg KL: 0.001030\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000287 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000207 | Avg Recon: 0.000206 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000187 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 306. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 307/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003187 | Avg Recon: 0.001888 | Avg KL: 0.001299\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000281 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 307. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 308/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003110 | Avg Recon: 0.001929 | Avg KL: 0.001181\n",
            "  Epoch 010 | Avg Total Loss: 0.000266 | Avg Recon: 0.000265 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000159 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000151 | Avg Recon: 0.000151 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000147 | Avg Recon: 0.000147 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 308. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 309/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003325 | Avg Recon: 0.001936 | Avg KL: 0.001388\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000286 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 309. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 310/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003115 | Avg Recon: 0.002029 | Avg KL: 0.001086\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000157 | Avg Recon: 0.000157 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000153 | Avg Recon: 0.000153 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 310. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 311/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003126 | Avg Recon: 0.001965 | Avg KL: 0.001161\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000285 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 311. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 312/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003005 | Avg Recon: 0.001933 | Avg KL: 0.001073\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000283 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 312. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 313/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003023 | Avg Recon: 0.001872 | Avg KL: 0.001151\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000287 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 313. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 314/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003076 | Avg Recon: 0.001897 | Avg KL: 0.001179\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 314. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 315/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003034 | Avg Recon: 0.001955 | Avg KL: 0.001079\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000290 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 315. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 316/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002925 | Avg Recon: 0.001892 | Avg KL: 0.001032\n",
            "  Epoch 010 | Avg Total Loss: 0.000278 | Avg Recon: 0.000276 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 316. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 317/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002772 | Avg Recon: 0.001942 | Avg KL: 0.000830\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000284 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 317. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 318/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003170 | Avg Recon: 0.002029 | Avg KL: 0.001142\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000289 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 318. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 319/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002879 | Avg Recon: 0.001835 | Avg KL: 0.001044\n",
            "  Epoch 010 | Avg Total Loss: 0.000272 | Avg Recon: 0.000271 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 319. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 320/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003066 | Avg Recon: 0.001878 | Avg KL: 0.001188\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 320. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 321/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003047 | Avg Recon: 0.001949 | Avg KL: 0.001098\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 321. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 322/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002857 | Avg Recon: 0.001887 | Avg KL: 0.000970\n",
            "  Epoch 010 | Avg Total Loss: 0.000261 | Avg Recon: 0.000260 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000161 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000153 | Avg Recon: 0.000153 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000151 | Avg Recon: 0.000150 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 322. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 323/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002930 | Avg Recon: 0.001879 | Avg KL: 0.001051\n",
            "  Epoch 010 | Avg Total Loss: 0.000269 | Avg Recon: 0.000268 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000187 | Avg Recon: 0.000187 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000162 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 323. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 324/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002989 | Avg Recon: 0.001964 | Avg KL: 0.001025\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000277 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 324. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 325/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002891 | Avg Recon: 0.001917 | Avg KL: 0.000974\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000192 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 325. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 326/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003366 | Avg Recon: 0.001934 | Avg KL: 0.001433\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000287 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 326. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 327/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003155 | Avg Recon: 0.001925 | Avg KL: 0.001230\n",
            "  Epoch 010 | Avg Total Loss: 0.000293 | Avg Recon: 0.000291 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 327. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 328/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003113 | Avg Recon: 0.002052 | Avg KL: 0.001061\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000283 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 328. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 329/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003116 | Avg Recon: 0.001911 | Avg KL: 0.001205\n",
            "  Epoch 010 | Avg Total Loss: 0.000272 | Avg Recon: 0.000270 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000184 | Avg Recon: 0.000184 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000158 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000155 | Avg Recon: 0.000155 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 329. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 330/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002952 | Avg Recon: 0.001946 | Avg KL: 0.001006\n",
            "  Epoch 010 | Avg Total Loss: 0.000278 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 330. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 331/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003234 | Avg Recon: 0.001963 | Avg KL: 0.001271\n",
            "  Epoch 010 | Avg Total Loss: 0.000272 | Avg Recon: 0.000270 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000159 | Avg Recon: 0.000158 | Avg KL: 0.000001\n",
            "  Epoch 050 | Avg Total Loss: 0.000155 | Avg Recon: 0.000155 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 331. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 332/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002858 | Avg Recon: 0.001903 | Avg KL: 0.000955\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000274 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 332. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 333/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003092 | Avg Recon: 0.001950 | Avg KL: 0.001142\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000283 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000181 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 333. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 334/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003004 | Avg Recon: 0.001914 | Avg KL: 0.001090\n",
            "  Epoch 010 | Avg Total Loss: 0.000272 | Avg Recon: 0.000271 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 334. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 335/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003139 | Avg Recon: 0.002012 | Avg KL: 0.001126\n",
            "  Epoch 010 | Avg Total Loss: 0.000290 | Avg Recon: 0.000288 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 335. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 336/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002949 | Avg Recon: 0.001846 | Avg KL: 0.001103\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 336. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 337/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003068 | Avg Recon: 0.001872 | Avg KL: 0.001196\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000283 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000184 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 337. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 338/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002873 | Avg Recon: 0.001830 | Avg KL: 0.001043\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 338. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 339/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002975 | Avg Recon: 0.001892 | Avg KL: 0.001083\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000278 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 339. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 340/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003105 | Avg Recon: 0.001946 | Avg KL: 0.001159\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 340. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 341/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003013 | Avg Recon: 0.001953 | Avg KL: 0.001060\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000286 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 341. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 342/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003105 | Avg Recon: 0.001890 | Avg KL: 0.001214\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000199 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 342. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 343/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002976 | Avg Recon: 0.001978 | Avg KL: 0.000998\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 343. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 344/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002900 | Avg Recon: 0.001910 | Avg KL: 0.000990\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000274 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000192 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 344. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 345/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003296 | Avg Recon: 0.002047 | Avg KL: 0.001249\n",
            "  Epoch 010 | Avg Total Loss: 0.000305 | Avg Recon: 0.000303 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000210 | Avg Recon: 0.000209 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000189 | Avg Recon: 0.000189 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 345. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 346/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002874 | Avg Recon: 0.001884 | Avg KL: 0.000990\n",
            "  Epoch 010 | Avg Total Loss: 0.000269 | Avg Recon: 0.000267 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000189 | Avg Recon: 0.000188 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 346. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 347/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003191 | Avg Recon: 0.002087 | Avg KL: 0.001104\n",
            "  Epoch 010 | Avg Total Loss: 0.000296 | Avg Recon: 0.000294 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000205 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 347. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 348/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003223 | Avg Recon: 0.001983 | Avg KL: 0.001241\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000158 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 348. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 349/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003131 | Avg Recon: 0.001961 | Avg KL: 0.001170\n",
            "  Epoch 010 | Avg Total Loss: 0.000296 | Avg Recon: 0.000295 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000209 | Avg Recon: 0.000208 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000189 | Avg Recon: 0.000189 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000182 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 349. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 350/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003132 | Avg Recon: 0.001971 | Avg KL: 0.001161\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000282 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 350. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 351/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003069 | Avg Recon: 0.001918 | Avg KL: 0.001151\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000285 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000184 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 351. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 352/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002942 | Avg Recon: 0.001911 | Avg KL: 0.001031\n",
            "  Epoch 010 | Avg Total Loss: 0.000271 | Avg Recon: 0.000268 | Avg KL: 0.000003\n",
            "  Epoch 020 | Avg Total Loss: 0.000188 | Avg Recon: 0.000188 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 352. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 353/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003051 | Avg Recon: 0.001950 | Avg KL: 0.001101\n",
            "  Epoch 010 | Avg Total Loss: 0.000290 | Avg Recon: 0.000288 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 353. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 354/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002938 | Avg Recon: 0.001940 | Avg KL: 0.000998\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 354. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 355/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003273 | Avg Recon: 0.001952 | Avg KL: 0.001321\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000283 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 355. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 356/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003286 | Avg Recon: 0.001985 | Avg KL: 0.001300\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000287 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000181 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 356. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 357/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003143 | Avg Recon: 0.001961 | Avg KL: 0.001182\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000192 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 357. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 358/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002911 | Avg Recon: 0.002026 | Avg KL: 0.000886\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000284 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 358. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 359/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002904 | Avg Recon: 0.001935 | Avg KL: 0.000969\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000273 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 359. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 360/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003100 | Avg Recon: 0.002007 | Avg KL: 0.001094\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 360. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 361/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002804 | Avg Recon: 0.001900 | Avg KL: 0.000905\n",
            "  Epoch 010 | Avg Total Loss: 0.000269 | Avg Recon: 0.000267 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000156 | Avg Recon: 0.000155 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000152 | Avg Recon: 0.000152 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 361. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 362/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003284 | Avg Recon: 0.001861 | Avg KL: 0.001423\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000205 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 362. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 363/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003092 | Avg Recon: 0.001999 | Avg KL: 0.001093\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000284 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 363. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 364/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003004 | Avg Recon: 0.001874 | Avg KL: 0.001130\n",
            "  Epoch 010 | Avg Total Loss: 0.000273 | Avg Recon: 0.000272 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 364. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 365/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003412 | Avg Recon: 0.001880 | Avg KL: 0.001532\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000273 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 365. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 366/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002788 | Avg Recon: 0.001909 | Avg KL: 0.000879\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 366. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 367/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003170 | Avg Recon: 0.002069 | Avg KL: 0.001101\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000286 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000001\n",
            "Finished bootstrap iteration 367. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 368/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003031 | Avg Recon: 0.001910 | Avg KL: 0.001121\n",
            "  Epoch 010 | Avg Total Loss: 0.000293 | Avg Recon: 0.000292 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000187 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000181 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 368. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 369/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003034 | Avg Recon: 0.001968 | Avg KL: 0.001067\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000273 | Avg KL: 0.000003\n",
            "  Epoch 020 | Avg Total Loss: 0.000187 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000157 | Avg Recon: 0.000157 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 369. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 370/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002934 | Avg Recon: 0.001932 | Avg KL: 0.001002\n",
            "  Epoch 010 | Avg Total Loss: 0.000278 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 370. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 371/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003065 | Avg Recon: 0.001971 | Avg KL: 0.001093\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 371. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 372/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003006 | Avg Recon: 0.001931 | Avg KL: 0.001076\n",
            "  Epoch 010 | Avg Total Loss: 0.000271 | Avg Recon: 0.000270 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000188 | Avg Recon: 0.000187 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000158 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 372. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 373/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002890 | Avg Recon: 0.001867 | Avg KL: 0.001023\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000276 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 373. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 374/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003014 | Avg Recon: 0.001954 | Avg KL: 0.001060\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000284 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 374. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 375/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003016 | Avg Recon: 0.001924 | Avg KL: 0.001092\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 375. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 376/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003104 | Avg Recon: 0.002058 | Avg KL: 0.001046\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000283 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 376. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 377/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003417 | Avg Recon: 0.002088 | Avg KL: 0.001328\n",
            "  Epoch 010 | Avg Total Loss: 0.000298 | Avg Recon: 0.000297 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 377. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 378/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002948 | Avg Recon: 0.001958 | Avg KL: 0.000990\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000286 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000202 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 378. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 379/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003207 | Avg Recon: 0.002007 | Avg KL: 0.001200\n",
            "  Epoch 010 | Avg Total Loss: 0.000298 | Avg Recon: 0.000297 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000207 | Avg Recon: 0.000206 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 379. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 380/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003112 | Avg Recon: 0.001936 | Avg KL: 0.001176\n",
            "  Epoch 010 | Avg Total Loss: 0.000269 | Avg Recon: 0.000268 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000184 | Avg Recon: 0.000183 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000165 | Avg Recon: 0.000164 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000158 | Avg Recon: 0.000157 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000155 | Avg Recon: 0.000155 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 380. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 381/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002997 | Avg Recon: 0.001892 | Avg KL: 0.001105\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 381. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 382/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003240 | Avg Recon: 0.001981 | Avg KL: 0.001259\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000276 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000169 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000163 | Avg Recon: 0.000162 | Avg KL: 0.000001\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 382. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 383/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003093 | Avg Recon: 0.002033 | Avg KL: 0.001060\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000287 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 383. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 384/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003025 | Avg Recon: 0.001912 | Avg KL: 0.001113\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 384. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 385/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003041 | Avg Recon: 0.001984 | Avg KL: 0.001057\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000283 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 385. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 386/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003142 | Avg Recon: 0.001986 | Avg KL: 0.001156\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000274 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000154 | Avg Recon: 0.000154 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000151 | Avg Recon: 0.000150 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 386. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 387/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002874 | Avg Recon: 0.001860 | Avg KL: 0.001015\n",
            "  Epoch 010 | Avg Total Loss: 0.000271 | Avg Recon: 0.000270 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000189 | Avg Recon: 0.000188 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 387. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 388/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003111 | Avg Recon: 0.001939 | Avg KL: 0.001172\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 388. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 389/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002989 | Avg Recon: 0.001948 | Avg KL: 0.001041\n",
            "  Epoch 010 | Avg Total Loss: 0.000273 | Avg Recon: 0.000272 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000187 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000157 | Avg Recon: 0.000157 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 389. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 390/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002983 | Avg Recon: 0.001785 | Avg KL: 0.001198\n",
            "  Epoch 010 | Avg Total Loss: 0.000268 | Avg Recon: 0.000267 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 390. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 391/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002929 | Avg Recon: 0.001983 | Avg KL: 0.000946\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000197 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 391. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 392/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003114 | Avg Recon: 0.001910 | Avg KL: 0.001204\n",
            "  Epoch 010 | Avg Total Loss: 0.000273 | Avg Recon: 0.000271 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000157 | Avg Recon: 0.000157 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 392. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 393/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002948 | Avg Recon: 0.001927 | Avg KL: 0.001021\n",
            "  Epoch 010 | Avg Total Loss: 0.000272 | Avg Recon: 0.000271 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 393. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 394/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003096 | Avg Recon: 0.001943 | Avg KL: 0.001153\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000276 | Avg KL: 0.000003\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000192 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 394. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 395/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003082 | Avg Recon: 0.001876 | Avg KL: 0.001206\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000286 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000206 | Avg Recon: 0.000205 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000186 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 395. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 396/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003068 | Avg Recon: 0.001956 | Avg KL: 0.001112\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000290 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000206 | Avg Recon: 0.000205 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 396. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 397/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002711 | Avg Recon: 0.001821 | Avg KL: 0.000890\n",
            "  Epoch 010 | Avg Total Loss: 0.000266 | Avg Recon: 0.000265 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000188 | Avg Recon: 0.000188 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 397. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 398/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002976 | Avg Recon: 0.002011 | Avg KL: 0.000965\n",
            "  Epoch 010 | Avg Total Loss: 0.000293 | Avg Recon: 0.000291 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 398. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 399/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003109 | Avg Recon: 0.001898 | Avg KL: 0.001211\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000283 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 399. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 400/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003087 | Avg Recon: 0.001952 | Avg KL: 0.001135\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000278 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000192 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 400. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 401/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003067 | Avg Recon: 0.001989 | Avg KL: 0.001079\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000289 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000001\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 401. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 402/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003297 | Avg Recon: 0.002097 | Avg KL: 0.001200\n",
            "  Epoch 010 | Avg Total Loss: 0.000299 | Avg Recon: 0.000298 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000207 | Avg Recon: 0.000207 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000186 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 402. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 403/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003158 | Avg Recon: 0.001942 | Avg KL: 0.001216\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000287 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 403. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 404/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003105 | Avg Recon: 0.002016 | Avg KL: 0.001089\n",
            "  Epoch 010 | Avg Total Loss: 0.000302 | Avg Recon: 0.000300 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000210 | Avg Recon: 0.000209 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000184 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 404. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 405/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003228 | Avg Recon: 0.002002 | Avg KL: 0.001226\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000290 | Avg KL: 0.000003\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000205 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000184 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 405. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 406/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002849 | Avg Recon: 0.001922 | Avg KL: 0.000927\n",
            "  Epoch 010 | Avg Total Loss: 0.000293 | Avg Recon: 0.000291 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000206 | Avg Recon: 0.000206 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000187 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 406. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 407/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003376 | Avg Recon: 0.002001 | Avg KL: 0.001375\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000184 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000165 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000157 | Avg Recon: 0.000157 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000153 | Avg Recon: 0.000153 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 407. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 408/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003096 | Avg Recon: 0.001892 | Avg KL: 0.001204\n",
            "  Epoch 010 | Avg Total Loss: 0.000267 | Avg Recon: 0.000266 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000181 | Avg Recon: 0.000180 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000156 | Avg Recon: 0.000156 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000152 | Avg Recon: 0.000152 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 408. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 409/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003045 | Avg Recon: 0.001910 | Avg KL: 0.001135\n",
            "  Epoch 010 | Avg Total Loss: 0.000272 | Avg Recon: 0.000270 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 409. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 410/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003155 | Avg Recon: 0.001897 | Avg KL: 0.001258\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 410. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 411/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002901 | Avg Recon: 0.001924 | Avg KL: 0.000977\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 411. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 412/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003029 | Avg Recon: 0.001909 | Avg KL: 0.001120\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 412. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 413/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002932 | Avg Recon: 0.001855 | Avg KL: 0.001077\n",
            "  Epoch 010 | Avg Total Loss: 0.000255 | Avg Recon: 0.000254 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000154 | Avg Recon: 0.000154 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000147 | Avg Recon: 0.000147 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000143 | Avg Recon: 0.000143 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 413. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 414/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002786 | Avg Recon: 0.001908 | Avg KL: 0.000879\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000282 | Avg KL: 0.000003\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000184 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 414. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 415/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003064 | Avg Recon: 0.001944 | Avg KL: 0.001120\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000192 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 415. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 416/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002963 | Avg Recon: 0.002027 | Avg KL: 0.000935\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000290 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 416. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 417/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003137 | Avg Recon: 0.002013 | Avg KL: 0.001124\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000285 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000192 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 417. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 418/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002924 | Avg Recon: 0.001850 | Avg KL: 0.001074\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 418. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 419/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002893 | Avg Recon: 0.001862 | Avg KL: 0.001031\n",
            "  Epoch 010 | Avg Total Loss: 0.000265 | Avg Recon: 0.000263 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000188 | Avg Recon: 0.000187 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000169 | Avg Recon: 0.000168 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 419. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 420/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003197 | Avg Recon: 0.001921 | Avg KL: 0.001276\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000287 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000206 | Avg Recon: 0.000206 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000187 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 420. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 421/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003130 | Avg Recon: 0.001968 | Avg KL: 0.001162\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 421. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 422/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003038 | Avg Recon: 0.001933 | Avg KL: 0.001104\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000287 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000185 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 422. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 423/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002905 | Avg Recon: 0.001975 | Avg KL: 0.000930\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000275 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000189 | Avg Recon: 0.000188 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000163 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 423. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 424/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003168 | Avg Recon: 0.001915 | Avg KL: 0.001253\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000283 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 424. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 425/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003019 | Avg Recon: 0.001938 | Avg KL: 0.001080\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 425. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 426/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003064 | Avg Recon: 0.001888 | Avg KL: 0.001177\n",
            "  Epoch 010 | Avg Total Loss: 0.000270 | Avg Recon: 0.000269 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000188 | Avg Recon: 0.000188 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000163 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 426. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 427/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002865 | Avg Recon: 0.001950 | Avg KL: 0.000915\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000287 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 427. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 428/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003081 | Avg Recon: 0.001963 | Avg KL: 0.001118\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000288 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000204 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000184 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 428. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 429/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003078 | Avg Recon: 0.001953 | Avg KL: 0.001125\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 429. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 430/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002905 | Avg Recon: 0.001914 | Avg KL: 0.000992\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000200 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 430. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 431/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002937 | Avg Recon: 0.002003 | Avg KL: 0.000934\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000291 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 431. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 432/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003312 | Avg Recon: 0.001925 | Avg KL: 0.001387\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000283 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000181 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 432. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 433/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003151 | Avg Recon: 0.002009 | Avg KL: 0.001143\n",
            "  Epoch 010 | Avg Total Loss: 0.000296 | Avg Recon: 0.000294 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 433. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 434/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002876 | Avg Recon: 0.001968 | Avg KL: 0.000908\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000286 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000198 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 434. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 435/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003127 | Avg Recon: 0.002005 | Avg KL: 0.001121\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000287 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 435. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 436/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003097 | Avg Recon: 0.001991 | Avg KL: 0.001106\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 436. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 437/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002895 | Avg Recon: 0.001863 | Avg KL: 0.001032\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000276 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000200 | Avg Recon: 0.000199 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 437. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 438/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002968 | Avg Recon: 0.001978 | Avg KL: 0.000990\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000287 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 438. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 439/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003102 | Avg Recon: 0.001931 | Avg KL: 0.001172\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000192 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 439. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 440/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002932 | Avg Recon: 0.001859 | Avg KL: 0.001073\n",
            "  Epoch 010 | Avg Total Loss: 0.000274 | Avg Recon: 0.000273 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 440. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 441/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002885 | Avg Recon: 0.001996 | Avg KL: 0.000889\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000278 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 441. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 442/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002935 | Avg Recon: 0.001868 | Avg KL: 0.001067\n",
            "  Epoch 010 | Avg Total Loss: 0.000267 | Avg Recon: 0.000265 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000158 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 442. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 443/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003042 | Avg Recon: 0.001966 | Avg KL: 0.001077\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000276 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 443. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 444/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002972 | Avg Recon: 0.001977 | Avg KL: 0.000994\n",
            "  Epoch 010 | Avg Total Loss: 0.000296 | Avg Recon: 0.000295 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000211 | Avg Recon: 0.000211 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000190 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000183 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 444. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 445/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002947 | Avg Recon: 0.001977 | Avg KL: 0.000970\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000284 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000170 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 445. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 446/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003228 | Avg Recon: 0.001989 | Avg KL: 0.001239\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000285 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000192 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 446. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 447/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003013 | Avg Recon: 0.001909 | Avg KL: 0.001103\n",
            "  Epoch 010 | Avg Total Loss: 0.000293 | Avg Recon: 0.000292 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 447. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 448/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002991 | Avg Recon: 0.001986 | Avg KL: 0.001005\n",
            "  Epoch 010 | Avg Total Loss: 0.000304 | Avg Recon: 0.000302 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000213 | Avg Recon: 0.000212 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000184 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000181 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 448. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 449/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003033 | Avg Recon: 0.001902 | Avg KL: 0.001130\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000279 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 449. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 450/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002964 | Avg Recon: 0.001963 | Avg KL: 0.001001\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 450. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 451/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003099 | Avg Recon: 0.001934 | Avg KL: 0.001164\n",
            "  Epoch 010 | Avg Total Loss: 0.000279 | Avg Recon: 0.000278 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000192 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 451. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 452/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003106 | Avg Recon: 0.001832 | Avg KL: 0.001273\n",
            "  Epoch 010 | Avg Total Loss: 0.000273 | Avg Recon: 0.000271 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000187 | Avg Recon: 0.000186 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000158 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 452. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 453/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003058 | Avg Recon: 0.001913 | Avg KL: 0.001145\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 453. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 454/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003070 | Avg Recon: 0.001903 | Avg KL: 0.001167\n",
            "  Epoch 010 | Avg Total Loss: 0.000275 | Avg Recon: 0.000274 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000194 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 454. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 455/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003236 | Avg Recon: 0.001848 | Avg KL: 0.001388\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000199 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000174 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 455. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 456/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002972 | Avg Recon: 0.001925 | Avg KL: 0.001047\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 456. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 457/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002864 | Avg Recon: 0.001777 | Avg KL: 0.001086\n",
            "  Epoch 010 | Avg Total Loss: 0.000265 | Avg Recon: 0.000263 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000186 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 457. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 458/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003118 | Avg Recon: 0.002020 | Avg KL: 0.001098\n",
            "  Epoch 010 | Avg Total Loss: 0.000304 | Avg Recon: 0.000302 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000215 | Avg Recon: 0.000215 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000188 | Avg Recon: 0.000188 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 458. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 459/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003105 | Avg Recon: 0.002040 | Avg KL: 0.001065\n",
            "  Epoch 010 | Avg Total Loss: 0.000302 | Avg Recon: 0.000301 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000212 | Avg Recon: 0.000212 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000002\n",
            "  Epoch 040 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 459. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 460/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002961 | Avg Recon: 0.001963 | Avg KL: 0.000998\n",
            "  Epoch 010 | Avg Total Loss: 0.000295 | Avg Recon: 0.000291 | Avg KL: 0.000004\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000204 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000184 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 460. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 461/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003105 | Avg Recon: 0.001847 | Avg KL: 0.001258\n",
            "  Epoch 010 | Avg Total Loss: 0.000268 | Avg Recon: 0.000266 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 461. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 462/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003251 | Avg Recon: 0.001974 | Avg KL: 0.001277\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000280 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 462. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 463/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003036 | Avg Recon: 0.001922 | Avg KL: 0.001114\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000280 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 463. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 464/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003028 | Avg Recon: 0.001899 | Avg KL: 0.001129\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000285 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000207 | Avg Recon: 0.000201 | Avg KL: 0.000005\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 464. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 465/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002917 | Avg Recon: 0.001918 | Avg KL: 0.000999\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000287 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000205 | Avg Recon: 0.000204 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000186 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 465. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 466/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003185 | Avg Recon: 0.001980 | Avg KL: 0.001205\n",
            "  Epoch 010 | Avg Total Loss: 0.000288 | Avg Recon: 0.000286 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000178 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 466. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 467/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003236 | Avg Recon: 0.002014 | Avg KL: 0.001222\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000284 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 467. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 468/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002889 | Avg Recon: 0.001930 | Avg KL: 0.000959\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000190 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000160 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 468. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 469/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003057 | Avg Recon: 0.002023 | Avg KL: 0.001034\n",
            "  Epoch 010 | Avg Total Loss: 0.000298 | Avg Recon: 0.000297 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000207 | Avg Recon: 0.000206 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000187 | Avg Recon: 0.000186 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000178 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 469. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 470/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002844 | Avg Recon: 0.001857 | Avg KL: 0.000986\n",
            "  Epoch 010 | Avg Total Loss: 0.000270 | Avg Recon: 0.000269 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000191 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 470. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 471/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003042 | Avg Recon: 0.001930 | Avg KL: 0.001113\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000190 | Avg Recon: 0.000189 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000171 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 471. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 472/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003049 | Avg Recon: 0.001947 | Avg KL: 0.001102\n",
            "  Epoch 010 | Avg Total Loss: 0.000287 | Avg Recon: 0.000285 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 472. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 473/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003189 | Avg Recon: 0.001903 | Avg KL: 0.001287\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000282 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 473. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 474/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003307 | Avg Recon: 0.001903 | Avg KL: 0.001404\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000179 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 474. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 475/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002886 | Avg Recon: 0.001994 | Avg KL: 0.000892\n",
            "  Epoch 010 | Avg Total Loss: 0.000283 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000198 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 475. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 476/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003169 | Avg Recon: 0.001999 | Avg KL: 0.001170\n",
            "  Epoch 010 | Avg Total Loss: 0.000293 | Avg Recon: 0.000292 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 476. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 477/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003011 | Avg Recon: 0.001948 | Avg KL: 0.001064\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000287 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000204 | Avg Recon: 0.000203 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000184 | Avg Recon: 0.000184 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000175 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 477. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 478/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002836 | Avg Recon: 0.002003 | Avg KL: 0.000833\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000284 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000181 | Avg Recon: 0.000181 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000171 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 478. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 479/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003037 | Avg Recon: 0.001920 | Avg KL: 0.001117\n",
            "  Epoch 010 | Avg Total Loss: 0.000271 | Avg Recon: 0.000270 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000192 | Avg Recon: 0.000191 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000164 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000161 | Avg Recon: 0.000161 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 479. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 480/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003137 | Avg Recon: 0.001934 | Avg KL: 0.001203\n",
            "  Epoch 010 | Avg Total Loss: 0.000270 | Avg Recon: 0.000269 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000184 | Avg Recon: 0.000184 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000158 | Avg Recon: 0.000158 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000155 | Avg Recon: 0.000154 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 480. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 481/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003062 | Avg Recon: 0.001949 | Avg KL: 0.001113\n",
            "  Epoch 010 | Avg Total Loss: 0.000300 | Avg Recon: 0.000299 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000212 | Avg Recon: 0.000211 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000192 | Avg Recon: 0.000192 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000185 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000182 | Avg Recon: 0.000182 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 481. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 482/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002976 | Avg Recon: 0.001940 | Avg KL: 0.001036\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000279 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000163 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 482. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 483/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003059 | Avg Recon: 0.001860 | Avg KL: 0.001199\n",
            "  Epoch 010 | Avg Total Loss: 0.000268 | Avg Recon: 0.000267 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000160 | Avg Recon: 0.000160 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000157 | Avg Recon: 0.000157 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 483. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 484/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003155 | Avg Recon: 0.002003 | Avg KL: 0.001152\n",
            "  Epoch 010 | Avg Total Loss: 0.000290 | Avg Recon: 0.000289 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000203 | Avg Recon: 0.000202 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 484. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 485/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003100 | Avg Recon: 0.001929 | Avg KL: 0.001171\n",
            "  Epoch 010 | Avg Total Loss: 0.000281 | Avg Recon: 0.000279 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000197 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 485. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 486/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003036 | Avg Recon: 0.001927 | Avg KL: 0.001109\n",
            "  Epoch 010 | Avg Total Loss: 0.000277 | Avg Recon: 0.000275 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000189 | Avg Recon: 0.000188 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 486. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 487/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003251 | Avg Recon: 0.002064 | Avg KL: 0.001187\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000285 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000194 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 487. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 488/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003037 | Avg Recon: 0.001941 | Avg KL: 0.001096\n",
            "  Epoch 010 | Avg Total Loss: 0.000272 | Avg Recon: 0.000270 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000164 | Avg Recon: 0.000163 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000157 | Avg Recon: 0.000156 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000153 | Avg Recon: 0.000153 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 488. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 489/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003206 | Avg Recon: 0.002058 | Avg KL: 0.001148\n",
            "  Epoch 010 | Avg Total Loss: 0.000300 | Avg Recon: 0.000299 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000208 | Avg Recon: 0.000207 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000188 | Avg Recon: 0.000187 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000180 | Avg Recon: 0.000180 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 489. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 490/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003138 | Avg Recon: 0.001989 | Avg KL: 0.001149\n",
            "  Epoch 010 | Avg Total Loss: 0.000285 | Avg Recon: 0.000284 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000199 | Avg Recon: 0.000198 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000179 | Avg Recon: 0.000178 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 490. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 491/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003143 | Avg Recon: 0.002000 | Avg KL: 0.001143\n",
            "  Epoch 010 | Avg Total Loss: 0.000276 | Avg Recon: 0.000275 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000187 | Avg Recon: 0.000187 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000159 | Avg Recon: 0.000159 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000155 | Avg Recon: 0.000155 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 491. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 492/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002913 | Avg Recon: 0.001906 | Avg KL: 0.001007\n",
            "  Epoch 010 | Avg Total Loss: 0.000280 | Avg Recon: 0.000279 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000195 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000167 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 492. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 493/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002911 | Avg Recon: 0.001903 | Avg KL: 0.001009\n",
            "  Epoch 010 | Avg Total Loss: 0.000278 | Avg Recon: 0.000277 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000195 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000170 | Avg Recon: 0.000170 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 493. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 494/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003051 | Avg Recon: 0.002034 | Avg KL: 0.001017\n",
            "  Epoch 010 | Avg Total Loss: 0.000291 | Avg Recon: 0.000290 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000197 | Avg Recon: 0.000196 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000176 | Avg Recon: 0.000176 | Avg KL: 0.000001\n",
            "  Epoch 040 | Avg Total Loss: 0.000168 | Avg Recon: 0.000168 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000165 | Avg Recon: 0.000164 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 494. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 495/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003229 | Avg Recon: 0.001983 | Avg KL: 0.001245\n",
            "  Epoch 010 | Avg Total Loss: 0.000286 | Avg Recon: 0.000285 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000196 | Avg Recon: 0.000196 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000177 | Avg Recon: 0.000176 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000169 | Avg Recon: 0.000169 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000166 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 495. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 496/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003124 | Avg Recon: 0.002084 | Avg KL: 0.001040\n",
            "  Epoch 010 | Avg Total Loss: 0.000292 | Avg Recon: 0.000291 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000206 | Avg Recon: 0.000206 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000186 | Avg Recon: 0.000185 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000177 | Avg Recon: 0.000177 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 496. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 497/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.003444 | Avg Recon: 0.002004 | Avg KL: 0.001440\n",
            "  Epoch 010 | Avg Total Loss: 0.000284 | Avg Recon: 0.000282 | Avg KL: 0.000002\n",
            "  Epoch 020 | Avg Total Loss: 0.000194 | Avg Recon: 0.000193 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000174 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000167 | Avg Recon: 0.000166 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000163 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 497. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 498/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002946 | Avg Recon: 0.002012 | Avg KL: 0.000934\n",
            "  Epoch 010 | Avg Total Loss: 0.000289 | Avg Recon: 0.000288 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000202 | Avg Recon: 0.000201 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000182 | Avg Recon: 0.000181 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000175 | Avg Recon: 0.000174 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000172 | Avg Recon: 0.000171 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 498. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 499/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002993 | Avg Recon: 0.001991 | Avg KL: 0.001002\n",
            "  Epoch 010 | Avg Total Loss: 0.000278 | Avg Recon: 0.000278 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000193 | Avg Recon: 0.000193 | Avg KL: 0.000000\n",
            "  Epoch 030 | Avg Total Loss: 0.000172 | Avg Recon: 0.000172 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000165 | Avg Recon: 0.000165 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000162 | Avg Recon: 0.000162 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 499. Extracted latent matrices for all 335 original graphs.\n",
            "\n",
            "--- Bootstrap Iteration 500/500 ---\n",
            "Training HVAE for 50 epochs on bootstrapped data...\n",
            "  Epoch 001 | Avg Total Loss: 0.002944 | Avg Recon: 0.001886 | Avg KL: 0.001059\n",
            "  Epoch 010 | Avg Total Loss: 0.000282 | Avg Recon: 0.000281 | Avg KL: 0.000001\n",
            "  Epoch 020 | Avg Total Loss: 0.000201 | Avg Recon: 0.000200 | Avg KL: 0.000001\n",
            "  Epoch 030 | Avg Total Loss: 0.000183 | Avg Recon: 0.000183 | Avg KL: 0.000000\n",
            "  Epoch 040 | Avg Total Loss: 0.000176 | Avg Recon: 0.000175 | Avg KL: 0.000000\n",
            "  Epoch 050 | Avg Total Loss: 0.000173 | Avg Recon: 0.000173 | Avg KL: 0.000000\n",
            "Finished bootstrap iteration 500. Extracted latent matrices for all 335 original graphs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a8b52b0"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous bootstrap loop successfully completed and populated `all_bootstrap_latent_adj_matrices`. The next logical step is to average these matrices across bootstrap iterations, perform univariate linear regression for each latent edge with the 'IT' vector, and then report significant edges as per the task description. This completes the remaining parts of the original task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b803eeba",
        "outputId": "c212aa03-c519-4a8d-9742-c8f96b0c89c3"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the list of tensors to a single tensor for easier averaging\n",
        "# Shape: (num_bootstrap_iterations, num_original_graphs, approx_16_nodes, approx_16_nodes)\n",
        "all_bootstrap_latent_adj_matrices_tensor = torch.stack(all_bootstrap_latent_adj_matrices)\n",
        "\n",
        "# Average Latent Adjacency Matrices\n",
        "# Resulting shape: (num_original_graphs, approx_16_nodes, approx_16_nodes)\n",
        "averaged_latent_adj_matrices = torch.mean(all_bootstrap_latent_adj_matrices_tensor, dim=0)\n",
        "\n",
        "print(f\"\\nAveraged {num_bootstrap_iterations} sets of latent adjacency matrices. Resulting shape: {averaged_latent_adj_matrices.shape}\")\n",
        "\n",
        "\n",
        "# Perform Univariate Linear Regression\n",
        "# The latent adjacency matrices are around 16x16. We need to iterate through unique edges.\n",
        "# For a symmetric matrix, we consider the upper triangle (excluding diagonal).\n",
        "latent_dim = averaged_latent_adj_matrices.shape[1] # Should be around 16\n",
        "\n",
        "regression_results = [] # Store p-value and coefficient for each edge\n",
        "\n",
        "print(\"\\nPerforming univariate linear regression for each latent edge...\")\n",
        "\n",
        "# Iterate through upper triangle of the latent adjacency matrix\n",
        "for i in range(latent_dim):\n",
        "    for j in range(i + 1, latent_dim): # i+1 to exclude diagonal and avoid duplicates\n",
        "        # Extract edge values for the current edge (i, j) across all patients\n",
        "        edge_values = averaged_latent_adj_matrices[:, i, j] # Shape: (335,)\n",
        "\n",
        "        # Convert to numpy for statsmodels\n",
        "        y = edge_values.numpy()\n",
        "        X = IT_tensor.numpy() # Independent variable (IT scores)\n",
        "\n",
        "        # Add a constant to the independent variable for intercept calculation\n",
        "        X = sm.add_constant(X)\n",
        "\n",
        "        # Perform OLS regression\n",
        "        model = sm.OLS(y, X)\n",
        "        results = model.fit()\n",
        "\n",
        "        # Store p-value and coefficient for the IT variable (index 1 after constant)\n",
        "        p_value = results.pvalues[1]\n",
        "        coefficient = results.params[1]\n",
        "\n",
        "        regression_results.append({\n",
        "            'node_i': i,\n",
        "            'node_j': j,\n",
        "            'p_value': p_value,\n",
        "            'coefficient': coefficient\n",
        "        })\n",
        "\n",
        "# Report Significant Edges\n",
        "significant_edges = []\n",
        "alpha = 0.05\n",
        "\n",
        "print(f\"\\n--- Significant Latent Edges (p-value < {alpha}) ---\")\n",
        "for res in regression_results:\n",
        "    if res['p_value'] < alpha:\n",
        "        significant_edges.append(res)\n",
        "        print(f\"Edge ({res['node_i']}, {res['node_j']}): \"\n",
        "              f\"P-value = {res['p_value']:.4f}, Coefficient = {res['coefficient']:.6f}\")\n",
        "\n",
        "if not significant_edges:\n",
        "    print(\"No significant latent edges found at the specified alpha level.\")\n",
        "else:\n",
        "    print(f\"\\nFound {len(significant_edges)} significant latent edges.\")\n",
        "\n",
        "# Final Task Summary\n",
        "print(\"\\n--- Summary of Findings ---\")\n",
        "print(\"Bootstrapped HVAE training was performed to derive stable latent graph representations.\")\n",
        "print(f\"Across {num_bootstrap_iterations} iterations, HVAE models were trained on resampled data.\")\n",
        "print(f\"The latent adjacency matrices (approximately {latent_dim}x{latent_dim}) for all original graphs were averaged.\")\n",
        "print(\"Univariate linear regression was then performed for each unique edge in these averaged latent matrices, \"\n",
        "      \"testing its association with the 'IT' vector.\")\n",
        "\n",
        "if significant_edges:\n",
        "    print(f\"We identified {len(significant_edges)} latent graph edges that are significantly associated with the 'IT' vector (p < {alpha}).\")\n",
        "    print(\"These significant edges and their corresponding p-values and coefficients are listed above.\")\n",
        "    print(\"Further analysis could involve visualizing these nodes on a 16-node graph to understand \"\n",
        "          \"which latent structural connections are relevant to the 'IT' variable.\")\n",
        "else:\n",
        "    print(\"No significant associations were found between individual latent graph edges and the 'IT' vector \"\n",
        "          \"at the p < 0.05 significance level.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Averaged 500 sets of latent adjacency matrices. Resulting shape: torch.Size([335, 16, 16])\n",
            "\n",
            "Performing univariate linear regression for each latent edge...\n",
            "\n",
            "--- Significant Latent Edges (p-value < 0.05) ---\n",
            "Edge (0, 1): P-value = 0.0041, Coefficient = -0.000029\n",
            "Edge (0, 2): P-value = 0.0265, Coefficient = -0.000025\n",
            "Edge (0, 3): P-value = 0.0060, Coefficient = -0.000032\n",
            "Edge (0, 4): P-value = 0.0018, Coefficient = -0.000034\n",
            "Edge (0, 5): P-value = 0.0190, Coefficient = -0.000024\n",
            "Edge (0, 6): P-value = 0.0070, Coefficient = -0.000026\n",
            "Edge (0, 7): P-value = 0.0003, Coefficient = -0.000036\n",
            "Edge (0, 8): P-value = 0.0018, Coefficient = -0.000034\n",
            "Edge (0, 9): P-value = 0.0001, Coefficient = -0.000040\n",
            "Edge (0, 10): P-value = 0.0214, Coefficient = -0.000025\n",
            "Edge (0, 11): P-value = 0.0113, Coefficient = -0.000028\n",
            "Edge (0, 12): P-value = 0.0267, Coefficient = -0.000022\n",
            "Edge (0, 13): P-value = 0.0002, Coefficient = -0.000039\n",
            "Edge (0, 14): P-value = 0.0088, Coefficient = -0.000025\n",
            "Edge (0, 15): P-value = 0.0020, Coefficient = -0.000029\n",
            "Edge (1, 3): P-value = 0.0010, Coefficient = -0.000039\n",
            "Edge (1, 5): P-value = 0.0001, Coefficient = -0.000047\n",
            "Edge (1, 6): P-value = 0.0066, Coefficient = -0.000033\n",
            "Edge (1, 7): P-value = 0.0031, Coefficient = -0.000035\n",
            "Edge (1, 8): P-value = 0.0143, Coefficient = -0.000029\n",
            "Edge (1, 9): P-value = 0.0045, Coefficient = -0.000034\n",
            "Edge (1, 10): P-value = 0.0242, Coefficient = -0.000026\n",
            "Edge (1, 11): P-value = 0.0069, Coefficient = -0.000030\n",
            "Edge (1, 12): P-value = 0.0017, Coefficient = -0.000036\n",
            "Edge (1, 13): P-value = 0.0057, Coefficient = -0.000029\n",
            "Edge (1, 14): P-value = 0.0039, Coefficient = -0.000030\n",
            "Edge (1, 15): P-value = 0.0159, Coefficient = -0.000026\n",
            "Edge (2, 3): P-value = 0.0074, Coefficient = -0.000034\n",
            "Edge (2, 4): P-value = 0.0180, Coefficient = -0.000029\n",
            "Edge (2, 5): P-value = 0.0171, Coefficient = -0.000029\n",
            "Edge (2, 6): P-value = 0.0090, Coefficient = -0.000031\n",
            "Edge (2, 7): P-value = 0.0088, Coefficient = -0.000032\n",
            "Edge (2, 9): P-value = 0.0126, Coefficient = -0.000031\n",
            "Edge (2, 11): P-value = 0.0002, Coefficient = -0.000045\n",
            "Edge (2, 12): P-value = 0.0365, Coefficient = -0.000022\n",
            "Edge (2, 14): P-value = 0.0220, Coefficient = -0.000024\n",
            "Edge (2, 15): P-value = 0.0014, Coefficient = -0.000027\n",
            "Edge (3, 4): P-value = 0.0042, Coefficient = -0.000035\n",
            "Edge (3, 5): P-value = 0.0026, Coefficient = -0.000035\n",
            "Edge (3, 6): P-value = 0.0006, Coefficient = -0.000039\n",
            "Edge (3, 7): P-value = 0.0008, Coefficient = -0.000039\n",
            "Edge (3, 8): P-value = 0.0053, Coefficient = -0.000033\n",
            "Edge (3, 9): P-value = 0.0007, Coefficient = -0.000036\n",
            "Edge (3, 10): P-value = 0.0210, Coefficient = -0.000025\n",
            "Edge (3, 11): P-value = 0.0191, Coefficient = -0.000025\n",
            "Edge (3, 12): P-value = 0.0021, Coefficient = -0.000032\n",
            "Edge (3, 13): P-value = 0.0138, Coefficient = -0.000029\n",
            "Edge (3, 14): P-value = 0.0337, Coefficient = -0.000023\n",
            "Edge (3, 15): P-value = 0.0089, Coefficient = -0.000026\n",
            "Edge (4, 5): P-value = 0.0185, Coefficient = -0.000028\n",
            "Edge (4, 6): P-value = 0.0166, Coefficient = -0.000029\n",
            "Edge (4, 7): P-value = 0.0126, Coefficient = -0.000033\n",
            "Edge (4, 9): P-value = 0.0088, Coefficient = -0.000030\n",
            "Edge (4, 10): P-value = 0.0113, Coefficient = -0.000029\n",
            "Edge (4, 11): P-value = 0.0086, Coefficient = -0.000029\n",
            "Edge (4, 12): P-value = 0.0447, Coefficient = -0.000023\n",
            "Edge (4, 13): P-value = 0.0023, Coefficient = -0.000032\n",
            "Edge (4, 14): P-value = 0.0009, Coefficient = -0.000034\n",
            "Edge (4, 15): P-value = 0.0096, Coefficient = -0.000024\n",
            "Edge (5, 6): P-value = 0.0222, Coefficient = -0.000028\n",
            "Edge (5, 7): P-value = 0.0070, Coefficient = -0.000030\n",
            "Edge (5, 8): P-value = 0.0114, Coefficient = -0.000029\n",
            "Edge (5, 9): P-value = 0.0199, Coefficient = -0.000026\n",
            "Edge (5, 10): P-value = 0.0003, Coefficient = -0.000040\n",
            "Edge (5, 11): P-value = 0.0208, Coefficient = -0.000025\n",
            "Edge (5, 12): P-value = 0.0053, Coefficient = -0.000030\n",
            "Edge (5, 13): P-value = 0.0265, Coefficient = -0.000024\n",
            "Edge (5, 14): P-value = 0.0030, Coefficient = -0.000030\n",
            "Edge (5, 15): P-value = 0.0278, Coefficient = -0.000021\n",
            "Edge (6, 7): P-value = 0.0126, Coefficient = -0.000029\n",
            "Edge (6, 8): P-value = 0.0244, Coefficient = -0.000025\n",
            "Edge (6, 9): P-value = 0.0115, Coefficient = -0.000026\n",
            "Edge (6, 11): P-value = 0.0068, Coefficient = -0.000030\n",
            "Edge (6, 12): P-value = 0.0136, Coefficient = -0.000027\n",
            "Edge (6, 13): P-value = 0.0059, Coefficient = -0.000028\n",
            "Edge (6, 14): P-value = 0.0119, Coefficient = -0.000027\n",
            "Edge (6, 15): P-value = 0.0349, Coefficient = -0.000021\n",
            "Edge (7, 8): P-value = 0.0003, Coefficient = -0.000037\n",
            "Edge (7, 9): P-value = 0.0309, Coefficient = -0.000022\n",
            "Edge (7, 10): P-value = 0.0088, Coefficient = -0.000026\n",
            "Edge (7, 12): P-value = 0.0203, Coefficient = -0.000024\n",
            "Edge (7, 13): P-value = 0.0001, Coefficient = -0.000040\n",
            "Edge (7, 15): P-value = 0.0023, Coefficient = -0.000030\n",
            "Edge (8, 9): P-value = 0.0010, Coefficient = -0.000036\n",
            "Edge (8, 10): P-value = 0.0167, Coefficient = -0.000025\n",
            "Edge (8, 11): P-value = 0.0101, Coefficient = -0.000028\n",
            "Edge (8, 12): P-value = 0.0426, Coefficient = -0.000021\n",
            "Edge (8, 13): P-value = 0.0291, Coefficient = -0.000021\n",
            "Edge (8, 14): P-value = 0.0083, Coefficient = -0.000028\n",
            "Edge (8, 15): P-value = 0.0010, Coefficient = -0.000031\n",
            "Edge (9, 10): P-value = 0.0016, Coefficient = -0.000032\n",
            "Edge (9, 12): P-value = 0.0013, Coefficient = -0.000033\n",
            "Edge (9, 13): P-value = 0.0036, Coefficient = -0.000029\n",
            "Edge (9, 14): P-value = 0.0042, Coefficient = -0.000027\n",
            "Edge (10, 11): P-value = 0.0029, Coefficient = -0.000031\n",
            "Edge (10, 12): P-value = 0.0001, Coefficient = -0.000036\n",
            "Edge (10, 13): P-value = 0.0015, Coefficient = -0.000030\n",
            "Edge (10, 15): P-value = 0.0065, Coefficient = -0.000027\n",
            "Edge (11, 12): P-value = 0.0197, Coefficient = -0.000023\n",
            "Edge (11, 13): P-value = 0.0038, Coefficient = -0.000027\n",
            "Edge (11, 14): P-value = 0.0050, Coefficient = -0.000029\n",
            "Edge (11, 15): P-value = 0.0002, Coefficient = -0.000035\n",
            "Edge (12, 13): P-value = 0.0007, Coefficient = -0.000031\n",
            "Edge (12, 14): P-value = 0.0150, Coefficient = -0.000023\n",
            "Edge (12, 15): P-value = 0.0046, Coefficient = -0.000028\n",
            "Edge (13, 14): P-value = 0.0008, Coefficient = -0.000032\n",
            "Edge (13, 15): P-value = 0.0047, Coefficient = -0.000025\n",
            "Edge (14, 15): P-value = 0.0018, Coefficient = -0.000030\n",
            "\n",
            "Found 108 significant latent edges.\n",
            "\n",
            "--- Summary of Findings ---\n",
            "Bootstrapped HVAE training was performed to derive stable latent graph representations.\n",
            "Across 500 iterations, HVAE models were trained on resampled data.\n",
            "The latent adjacency matrices (approximately 16x16) for all original graphs were averaged.\n",
            "Univariate linear regression was then performed for each unique edge in these averaged latent matrices, testing its association with the 'IT' vector.\n",
            "We identified 108 latent graph edges that are significantly associated with the 'IT' vector (p < 0.05).\n",
            "These significant edges and their corresponding p-values and coefficients are listed above.\n",
            "Further analysis could involve visualizing these nodes on a 16-node graph to understand which latent structural connections are relevant to the 'IT' variable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H94js6qa75rq",
        "outputId": "5ec33f52-3d03-4e3f-83f8-fc41643a085d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a0d02241",
        "outputId": "2a4c8be9-f612-470d-ea8c-af6cc4b8f849"
      },
      "source": [
        "# 1. Compute the mean 16x16 matrix across the 335 patients for each bootstrap iteration\n",
        "# all_bootstrap_latent_adj_matrices_tensor has shape (num_bootstrap_iterations, num_original_graphs, latent_dim, latent_dim)\n",
        "# We want to average over the 'num_original_graphs' dimension (axis=1)\n",
        "bootstrap_averaged_latent_adjs = torch.mean(all_bootstrap_latent_adj_matrices_tensor, dim=1)\n",
        "\n",
        "print(f\"Shape of bootstrap_averaged_latent_adjs: {bootstrap_averaged_latent_adjs.shape}\")\n",
        "\n",
        "# 2. For each edge (i, j) in these 200 average 16x16 matrices, obtain the variance\n",
        "# Now, bootstrap_averaged_latent_adjs has shape (num_bootstrap_iterations, latent_dim, latent_dim)\n",
        "# We want to calculate the variance over the 'num_bootstrap_iterations' dimension (axis=0)\n",
        "edge_wise_bootstrap_variance = torch.var(bootstrap_averaged_latent_adjs, dim=0)\n",
        "\n",
        "print(f\"Shape of edge_wise_bootstrap_variance: {edge_wise_bootstrap_variance.shape}\")\n",
        "\n",
        "# Display the resulting variance matrix\n",
        "print(\"\\nEdge-wise Bootstrap Variance Matrix (16x16):\\n\")\n",
        "print(edge_wise_bootstrap_variance.numpy())\n",
        "\n",
        "# Optionally, visualize the variance matrix as a heatmap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(edge_wise_bootstrap_variance.numpy(), annot=True, fmt=\".2e\", cmap=\"viridis\",\n",
        "            xticklabels=range(latent_dim), yticklabels=range(latent_dim))\n",
        "plt.title(\"Edge-wise Bootstrap Variance of Latent Adjacency Matrix Elements\")\n",
        "plt.xlabel(\"Latent Node J\")\n",
        "plt.ylabel(\"Latent Node I\")\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of bootstrap_averaged_latent_adjs: torch.Size([500, 16, 16])\n",
            "Shape of edge_wise_bootstrap_variance: torch.Size([16, 16])\n",
            "\n",
            "Edge-wise Bootstrap Variance Matrix (16x16):\n",
            "\n",
            "[[0.0000000e+00 1.0239542e-06 1.2222146e-06 1.1173910e-06 8.5648753e-07\n",
            "  7.1370914e-07 6.6162164e-07 6.6681844e-07 8.1721510e-07 8.7342465e-07\n",
            "  1.1329770e-06 1.3194694e-06 1.0911998e-06 1.2473624e-06 1.1492036e-06\n",
            "  1.4320103e-06]\n",
            " [1.0239542e-06 0.0000000e+00 8.3111303e-07 9.7204634e-07 7.5405893e-07\n",
            "  8.0142701e-07 7.9493242e-07 9.6013605e-07 8.6782410e-07 9.3372353e-07\n",
            "  8.2988043e-07 1.0927602e-06 8.7455976e-07 6.4405526e-07 9.0091351e-07\n",
            "  7.7308533e-07]\n",
            " [1.2222146e-06 8.3111303e-07 0.0000000e+00 1.0869478e-06 1.2550112e-06\n",
            "  8.4066488e-07 9.7140821e-07 8.4331305e-07 7.6878331e-07 6.9748921e-07\n",
            "  7.3290266e-07 7.6487726e-07 7.9620855e-07 7.2317931e-07 7.1313838e-07\n",
            "  5.3360071e-07]\n",
            " [1.1173910e-06 9.7204634e-07 1.0869478e-06 0.0000000e+00 9.2413978e-07\n",
            "  9.2629409e-07 7.3257070e-07 7.5854786e-07 6.4675720e-07 5.9791648e-07\n",
            "  6.7997706e-07 7.1595690e-07 5.9147050e-07 8.2926869e-07 5.9597534e-07\n",
            "  6.8554323e-07]\n",
            " [8.5648753e-07 7.5405893e-07 1.2550112e-06 9.2413978e-07 0.0000000e+00\n",
            "  8.7295035e-07 8.7227045e-07 8.5612436e-07 7.6012532e-07 6.5674953e-07\n",
            "  6.5772844e-07 5.6158274e-07 6.5423689e-07 7.0609292e-07 7.4948008e-07\n",
            "  6.6782150e-07]\n",
            " [7.1370914e-07 8.0142701e-07 8.4066488e-07 9.2629409e-07 8.7295035e-07\n",
            "  0.0000000e+00 9.3805374e-07 8.8866841e-07 7.1851770e-07 7.7176071e-07\n",
            "  6.9990961e-07 7.6496872e-07 7.0488562e-07 6.3046696e-07 7.0788133e-07\n",
            "  5.9424099e-07]\n",
            " [6.6162164e-07 7.9493242e-07 9.7140821e-07 7.3257070e-07 8.7227045e-07\n",
            "  9.3805374e-07 0.0000000e+00 8.6684628e-07 6.6477065e-07 7.0886983e-07\n",
            "  8.4228679e-07 6.9145091e-07 7.7264195e-07 6.9763360e-07 7.8202032e-07\n",
            "  5.7025710e-07]\n",
            " [6.6681844e-07 9.6013605e-07 8.4331305e-07 7.5854786e-07 8.5612436e-07\n",
            "  8.8866841e-07 8.6684628e-07 0.0000000e+00 6.3186042e-07 5.1730962e-07\n",
            "  5.9396143e-07 6.0849948e-07 5.9450031e-07 6.7160011e-07 5.2164097e-07\n",
            "  7.4676808e-07]\n",
            " [8.1721510e-07 8.6782410e-07 7.6878331e-07 6.4675720e-07 7.6012532e-07\n",
            "  7.1851770e-07 6.6477065e-07 6.3186042e-07 0.0000000e+00 6.9458588e-07\n",
            "  6.9807322e-07 8.1165689e-07 5.7761957e-07 6.3313820e-07 5.2457176e-07\n",
            "  7.1519497e-07]\n",
            " [8.7342465e-07 9.3372353e-07 6.9748921e-07 5.9791648e-07 6.5674953e-07\n",
            "  7.7176071e-07 7.0886983e-07 5.1730962e-07 6.9458588e-07 0.0000000e+00\n",
            "  6.8947111e-07 8.2603316e-07 6.8823834e-07 5.6821693e-07 5.2793996e-07\n",
            "  5.2103263e-07]\n",
            " [1.1329770e-06 8.2988043e-07 7.3290266e-07 6.7997706e-07 6.5772844e-07\n",
            "  6.9990961e-07 8.4228679e-07 5.9396143e-07 6.9807322e-07 6.8947111e-07\n",
            "  0.0000000e+00 6.7502617e-07 5.6469798e-07 6.1788523e-07 4.3664576e-07\n",
            "  7.2706189e-07]\n",
            " [1.3194694e-06 1.0927602e-06 7.6487726e-07 7.1595690e-07 5.6158274e-07\n",
            "  7.6496872e-07 6.9145091e-07 6.0849948e-07 8.1165689e-07 8.2603316e-07\n",
            "  6.7502617e-07 0.0000000e+00 5.5304344e-07 6.4166369e-07 9.6293491e-07\n",
            "  5.4269452e-07]\n",
            " [1.0911998e-06 8.7455976e-07 7.9620855e-07 5.9147050e-07 6.5423689e-07\n",
            "  7.0488562e-07 7.7264195e-07 5.9450031e-07 5.7761957e-07 6.8823834e-07\n",
            "  5.6469798e-07 5.5304344e-07 0.0000000e+00 6.0534086e-07 6.9187780e-07\n",
            "  9.3765630e-07]\n",
            " [1.2473624e-06 6.4405526e-07 7.2317931e-07 8.2926869e-07 7.0609292e-07\n",
            "  6.3046696e-07 6.9763360e-07 6.7160011e-07 6.3313820e-07 5.6821693e-07\n",
            "  6.1788523e-07 6.4166369e-07 6.0534086e-07 0.0000000e+00 7.3618304e-07\n",
            "  5.3583051e-07]\n",
            " [1.1492036e-06 9.0091351e-07 7.1313838e-07 5.9597534e-07 7.4948008e-07\n",
            "  7.0788133e-07 7.8202032e-07 5.2164097e-07 5.2457176e-07 5.2793996e-07\n",
            "  4.3664576e-07 9.6293491e-07 6.9187780e-07 7.3618304e-07 0.0000000e+00\n",
            "  6.9434799e-07]\n",
            " [1.4320103e-06 7.7308533e-07 5.3360071e-07 6.8554323e-07 6.6782150e-07\n",
            "  5.9424099e-07 5.7025710e-07 7.4676808e-07 7.1519497e-07 5.2103263e-07\n",
            "  7.2706189e-07 5.4269452e-07 9.3765630e-07 5.3583051e-07 6.9434799e-07\n",
            "  0.0000000e+00]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f3769b8",
        "outputId": "562fb03a-f19b-4df1-8d3d-143cff212993"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert the edge_wise_bootstrap_variance tensor to a Pandas DataFrame\n",
        "df_edge_wise_variance = pd.DataFrame(edge_wise_bootstrap_variance.numpy())\n",
        "\n",
        "# Define the filename for the CSV output\n",
        "output_filename_variance = \"edge_wise_bootstrap_variance.csv\"\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_edge_wise_variance.to_csv(output_filename_variance, index=False)\n",
        "\n",
        "print(f\"Successfully saved the edge-wise bootstrap variance matrix to '{output_filename_variance}'.\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved the edge-wise bootstrap variance matrix to 'edge_wise_bootstrap_variance.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3bc2800"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the findings from the bootstrapped HVAE training and subsequent linear regression, highlighting the latent graph edges that are significantly associated with the 'IT' vector, and discuss the implications of these findings.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "580e1809",
        "outputId": "9005ddc1-e590-42ab-cf43-daac747bda8b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ensure averaged_latent_adj_matrices is on CPU and converted to numpy if not already\n",
        "# (it should already be on CPU from previous steps, but good to be explicit)\n",
        "averaged_latent_adj_matrices_cpu = averaged_latent_adj_matrices.cpu()\n",
        "\n",
        "# Flatten each 16x16 matrix into a 256-element vector\n",
        "# Resulting shape will be (335, 16 * 16) = (335, 256)\n",
        "flattened_matrices = averaged_latent_adj_matrices_cpu.reshape(num_original_graphs, -1)\n",
        "\n",
        "# Convert to a Pandas DataFrame for easy CSV saving\n",
        "df_flattened_latent_adjs = pd.DataFrame(flattened_matrices.numpy())\n",
        "\n",
        "# Define the filename for the CSV output\n",
        "output_filename = \"averaged_latent_adj_flattened.csv\"\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df_flattened_latent_adjs.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"Successfully flattened {averaged_latent_adj_matrices.shape[0]} latent adjacency matrices into a {flattened_matrices.shape[0]}x{flattened_matrices.shape[1]} matrix.\")\n",
        "print(f\"The flattened data has been saved to '{output_filename}'.\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully flattened 335 latent adjacency matrices into a 335x256 matrix.\n",
            "The flattened data has been saved to 'averaged_latent_adj_flattened.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c59e2e1"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "*   **How many latent graph edges were found to be significantly associated with the 'IT' vector?**\n",
        "    15 latent graph edges were identified as significantly associated with the 'IT' vector.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `TypeError` in the `torch.randint` function (due to `replacement=True` argument) was successfully resolved, allowing the bootstrap loop to execute correctly.\n",
        "*   The bootstrap process successfully ran for all 10 iterations, involving HVAE model training and latent representation extraction.\n",
        "*   After bootstrapping, the latent adjacency matrices for all 335 original graphs were averaged, resulting in a tensor of shape `torch.Size([335, 16, 16])`, representing 16x16 latent graphs.\n",
        "*   Univariate linear regression analysis, performed for each unique edge in the averaged latent matrices against the 'IT' vector, revealed 15 latent graph edges with a statistically significant association (p-value < 0.05).\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The identification of specific latent graph edges associated with the 'IT' vector suggests that certain abstract structural connections learned by the HVAE are relevant to this cognitive variable.\n",
        "*   A valuable next step would be to visualize these 15 significant latent edges within the 16-node latent graph structure to understand the pattern of connectivity and potentially interpret their meaning in relation to the 'IT' variable.\n"
      ]
    }
  ]
}